{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4545486a",
   "metadata": {},
   "source": [
    "# Here are the method description:\n",
    "The core idea of this workflow is to construct all raw molecular features once, and for each random seed, fit all learnable transformations exclusively on the training set, thereby strictly preventing information leakage.\n",
    "\n",
    "First, the original CSV file is cleaned by retaining only SMILES strings and target properties (HOMO, LUMO, and bandgap), removing missing values and duplicate molecules, and enforcing numeric type consistency, yielding a cleaned dataset df_clean. SMILES strings are then converted into RDKit molecular objects, and invalid structures are discarded to obtain an RDKit-valid subset df_all_v.\n",
    "\n",
    "On this RDKit-valid subset, full molecular representations are constructed once, including Morgan fingerprints, MACCS keys, and raw RDKit descriptors (continuous features), together with the corresponding descriptor name list. These representations are treated as static raw feature matrices; for different random seeds, they are reused via index slicing without recomputation.\n",
    "\n",
    "For each random seed, train/test indices are first generated as NumPy integer arrays. This index split constitutes the sole branching point of the entire pipeline. Target variables are then sliced accordingly to obtain training and test labels.\n",
    "\n",
    "For sparse or binary features (Morgan fingerprints and MACCS keys), zero-variance and high-zero-fraction filters are fitted on the training subset only, and the resulting masks are applied to both training and test data. For continuous descriptors, variance filtering, correlation filtering, and feature scaling are all performed exclusively on the training subset, with the learned transformations subsequently applied to the test subset.\n",
    "\n",
    "For SELFIES-based representations, TF–IDF vectorizers are fitted using only training-set SMILES for each seed, and the learned vectorization is applied to the test set, optionally followed by sparsity-based filtering derived from the training data. This design ensures that both the vocabulary and feature weights originate strictly from training data.\n",
    "\n",
    "After these steps, Morgan, MACCS, SELFIES, and scaled descriptor features are combined to form nine feature-fusion configurations.\n",
    "\n",
    "For practical usability and reproducibility, all preprocessing, feature construction, splitting, filtering, scaling, fusion, and evaluation steps are encapsulated into modular functions, enabling the entire pipeline to be executed in an automated and fully reproducible manner.\n",
    "\n",
    "In the modeling stage, an exhaustive evaluation is conducted over 11 regression models, 9 feature representations, 4 prediction targets, and multiple random seeds. For each configuration, test-set performance is quantified using R^2, RMSE, MAE, and the bandgap discrepancy derived from HOMO/LUMO predictions (Delta_gap).\n",
    "\n",
    "Because direct bandgap prediction was empirically found to be inferior to predicting HOMO and LUMO separately followed by a physically consistent difference, an indirect gap-prediction strategy driven by HOMO/LUMO models is adopted. Optimal and stable model–feature combinations are selected independently for HOMO and LUMO. Final results are summarized across random seeds by reporting means and standard deviations.\n",
    "\n",
    "Multi-seed evaluation indicates that under strict leakage-free conditions, none of the configurations achieves a bandgap R^2 exceeding approximately 0.8, reflecting the intrinsic difficulty of the dataset and prediction task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5fe23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import selfies as sf\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import rdFingerprintGenerator, MACCSkeys, Descriptors\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool, GCNConv, GINEConv, NNConv\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import MatplotlibDeprecationWarning\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=MatplotlibDeprecationWarning)\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*'squared' is deprecated.*\",\n",
    "    category=FutureWarning\n",
    ")\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7042f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 load and clean csv all\n",
    "#\n",
    "\n",
    "def load_and_clean_csv_all(\n",
    "    csv_path,\n",
    "    smiles_col=\"smiles\",\n",
    "    targets=(\"homo\", \"lumo\", \"gap\"),\n",
    "    drop_duplicates=True,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load CSV and perform minimal global cleaning (scheme-2 ALL step).\n",
    "\n",
    "    This function DOES NOT split data.\n",
    "    It only:\n",
    "      - loads CSV\n",
    "      - keeps [smiles + targets]\n",
    "      - drops NaNs\n",
    "      - strips SMILES\n",
    "      - optionally removes duplicate SMILES\n",
    "      - coerces targets to float\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Path to CSV file.\n",
    "\n",
    "    smiles_col : str\n",
    "        Column name for SMILES.\n",
    "\n",
    "    targets : tuple/list\n",
    "        Target column names (e.g. (\"homo\",\"lumo\",\"gap\")).\n",
    "\n",
    "    drop_duplicates : bool\n",
    "        Whether to drop duplicate SMILES (recommended).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_clean : pd.DataFrame\n",
    "        Clean dataframe with columns [smiles_col + targets].\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- load\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # ---- column check\n",
    "    needed = [smiles_col] + list(targets)\n",
    "    missing = [c for c in needed if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns {missing}. Available: {list(df.columns)}\")\n",
    "\n",
    "    # ---- keep only needed columns\n",
    "    df = df[needed].copy()\n",
    "\n",
    "    # ---- drop NaNs\n",
    "    df = df.dropna(subset=needed).reset_index(drop=True)\n",
    "\n",
    "    # ---- clean SMILES\n",
    "    df[smiles_col] = df[smiles_col].astype(str).str.strip()\n",
    "    df = df[df[smiles_col] != \"\"].reset_index(drop=True)\n",
    "\n",
    "    # ---- optional: drop duplicate SMILES\n",
    "    if drop_duplicates:\n",
    "        before = len(df)\n",
    "        df = df.drop_duplicates(subset=[smiles_col]).reset_index(drop=True)\n",
    "        if verbose:\n",
    "            print(f\"Dropped {before - len(df)} duplicate SMILES\")\n",
    "\n",
    "    # ---- coerce targets to float\n",
    "    for t in targets:\n",
    "        df[t] = pd.to_numeric(df[t], errors=\"coerce\")\n",
    "\n",
    "    # ---- final NaN safety\n",
    "    df = df.dropna(subset=list(targets)).reset_index(drop=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"=== load_and_clean_csv_all ===\")\n",
    "        print(f\"CSV: {csv_path}\")\n",
    "        print(f\"SMILES column: {smiles_col}\")\n",
    "        print(f\"Targets: {list(targets)}\")\n",
    "        print(f\"Final molecule count: {len(df)}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c59bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 \n",
    "def rdkit_mol_valid_mask_all(df_clean, smiles_col=\"smiles\", verbose=True):\n",
    "    \"\"\"\n",
    "    Convert SMILES to RDKit Mol for ALL rows, build valid mask,\n",
    "    and return RDKit-valid subset.\n",
    "\n",
    "    Inputs:\n",
    "        df_clean   : DataFrame (already cleaned: smiles + targets, no NaN)\n",
    "        smiles_col: column name for SMILES\n",
    "\n",
    "    Returns:\n",
    "        mols_all   : pd.Series of RDKit Mol (invalid -> None), length = len(df_clean)\n",
    "        valid_mask: np.ndarray(bool), same length\n",
    "        df_all_v  : DataFrame, only RDKit-valid rows (reset index)\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- SMILES -> Mol (keep alignment with df_clean)\n",
    "    def _smiles_to_mol(s):\n",
    "        if not isinstance(s, str) or s.strip() == \"\":\n",
    "            return None\n",
    "        return Chem.MolFromSmiles(s)\n",
    "\n",
    "    mols_all = df_clean[smiles_col].apply(_smiles_to_mol)\n",
    "\n",
    "    # ---- valid mask\n",
    "    valid_mask = mols_all.notna().to_numpy()\n",
    "\n",
    "    n_total = len(mols_all)\n",
    "    n_valid = int(valid_mask.sum())\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"RDKit valid molecules: {n_valid} / {n_total}\")\n",
    "        if n_valid < n_total:\n",
    "            print(f\"Dropped {n_total - n_valid} invalid SMILES\")\n",
    "\n",
    "    # ---- keep only valid rows (for downstream features)\n",
    "    df_all_v = df_clean.loc[valid_mask].reset_index(drop=True)\n",
    "    mols_all_v = mols_all.loc[valid_mask].reset_index(drop=True)\n",
    "\n",
    "    return mols_all, valid_mask, df_all_v, mols_all_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6952a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "def build_rdkit_feature_blocks_all(\n",
    "    mols_all_v,\n",
    "    DESC_FUNCS,\n",
    "    build_morgan_var=True,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Build FULL RDKit feature matrices ONCE (scheme-2 'ALL' step).\n",
    "\n",
    "    Inputs:\n",
    "        mols_all_v : pd.Series of RDKit Mol, already RDKit-valid (no None)\n",
    "        DESC_FUNCS : list of (name, callable) for continuous descriptors\n",
    "        build_morgan_var : whether to also build Morgan(radius=3, fpSize=2048)\n",
    "        verbose : print shape report\n",
    "\n",
    "    Returns:\n",
    "        X_morgan_base_all : (N, 1024)\n",
    "        X_morgan_var_all  : (N, 2048) if build_morgan_var else None\n",
    "        X_maccs_all       : (N, 167)\n",
    "        X_desc_raw_all    : (N, D) where D=len(DESC_FUNCS), may contain NaN\n",
    "        desc_names        : list[str] length D\n",
    "    \"\"\"\n",
    "    # ---- safety: ensure Series\n",
    "    if not isinstance(mols_all_v, pd.Series):\n",
    "        mols_all_v = pd.Series(mols_all_v)\n",
    "\n",
    "    N = len(mols_all_v)\n",
    "    if N == 0:\n",
    "        raise ValueError(\"mols_all_v is empty.\")\n",
    "\n",
    "    # must be RDKit-valid\n",
    "    if mols_all_v.isna().any():\n",
    "        raise ValueError(\"mols_all_v contains NaN/None. Please filter to RDKit-valid mols first.\")\n",
    "\n",
    "    # ---- descriptor names\n",
    "    desc_names = [n for n, _ in DESC_FUNCS]\n",
    "    D = len(desc_names)\n",
    "\n",
    "   \n",
    "    # 1) Morgan base (1024)\n",
    "   \n",
    "    gen_base = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=1024)\n",
    "\n",
    "    fps_base = mols_all_v.apply(lambda m: gen_base.GetFingerprintAsNumPy(m))\n",
    "    if fps_base.isna().any():\n",
    "        raise ValueError(\"Morgan(base) produced NaN rows (unexpected if RDKit-valid).\")\n",
    "\n",
    "    X_morgan_base_all = np.stack(fps_base.to_numpy())\n",
    "    # shape check\n",
    "    if X_morgan_base_all.shape != (N, 1024):\n",
    "        raise ValueError(f\"Morgan(base) shape mismatch: got {X_morgan_base_all.shape}, expected {(N,1024)}\")\n",
    "\n",
    "    # 2) Morgan var (2048) optional\n",
    "    X_morgan_var_all = None\n",
    "    if build_morgan_var:\n",
    "        gen_var = rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=2048)\n",
    "        fps_var = mols_all_v.apply(lambda m: gen_var.GetFingerprintAsNumPy(m))\n",
    "        if fps_var.isna().any():\n",
    "            raise ValueError(\"Morgan(var) produced NaN rows (unexpected if RDKit-valid).\")\n",
    "        X_morgan_var_all = np.stack(fps_var.to_numpy())\n",
    "        if X_morgan_var_all.shape != (N, 2048):\n",
    "            raise ValueError(f\"Morgan(var) shape mismatch: got {X_morgan_var_all.shape}, expected {(N,2048)}\")\n",
    "\n",
    "    # 3) MACCS (167)\n",
    "    maccs_fp = mols_all_v.apply(lambda m: MACCSkeys.GenMACCSKeys(m))\n",
    "    if maccs_fp.isna().any():\n",
    "        raise ValueError(\"MACCS produced NaN rows (unexpected if RDKit-valid).\")\n",
    "\n",
    "    X_maccs_all = np.vstack([np.asarray(fp) for fp in maccs_fp.to_numpy()])\n",
    "    if X_maccs_all.shape != (N, 167):\n",
    "        raise ValueError(f\"MACCS shape mismatch: got {X_maccs_all.shape}, expected {(N,167)}\")\n",
    "\n",
    "    # 4) Descriptors raw (N×D), allow NaN but keep alignment\n",
    "    rows = []\n",
    "    bad_rows = 0\n",
    "\n",
    "    for m in mols_all_v:\n",
    "        vals = []\n",
    "        ok = True\n",
    "        for _, fn in DESC_FUNCS:\n",
    "            v = fn(m)\n",
    "            if v is None or (isinstance(v, float) and (np.isnan(v) or np.isinf(v))):\n",
    "                ok = False\n",
    "                break\n",
    "            vals.append(float(v))\n",
    "\n",
    "        if ok:\n",
    "            rows.append(vals)\n",
    "        else:\n",
    "            bad_rows += 1\n",
    "            rows.append([np.nan] * D)  # keep alignment\n",
    "\n",
    "    X_desc_raw_all = np.asarray(rows, dtype=float)\n",
    "    if X_desc_raw_all.shape != (N, D):\n",
    "        raise ValueError(f\"Desc(raw) shape mismatch: got {X_desc_raw_all.shape}, expected {(N,D)}\")\n",
    "\n",
    "    # final report\n",
    "    if verbose:\n",
    "        print(\"FULL RDKit feature blocks (scheme-2 ALL step):\")\n",
    "        print(\"  N molecules :\", N)\n",
    "        print(\"  Morgan base :\", X_morgan_base_all.shape)\n",
    "        print(\"  Morgan var  :\", None if X_morgan_var_all is None else X_morgan_var_all.shape)\n",
    "        print(\"  MACCS       :\", X_maccs_all.shape)\n",
    "        print(\"  Desc(raw)   :\", X_desc_raw_all.shape)\n",
    "        if bad_rows > 0:\n",
    "            print(f\"  [WARN] Descriptor invalid rows set to NaN: {bad_rows}\")\n",
    "        print(\"  desc_names  :\", len(desc_names))\n",
    "\n",
    "    return X_morgan_base_all, X_morgan_var_all, X_maccs_all, X_desc_raw_all, desc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c9a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "def make_train_test_indices(N, seed=42, test_size=0.2, stratify=None):\n",
    "    \"\"\"\n",
    "    Scheme-2 split (index-based).\n",
    "\n",
    "    Inputs:\n",
    "        N (int): number of samples in the full dataset (after cleaning + RDKit-valid filtering)\n",
    "        seed (int): random seed for reproducibility\n",
    "        test_size (float or int): fraction (0-1) or absolute number of test samples\n",
    "        stratify (array-like or None): optional labels for stratified split (length N)\n",
    "\n",
    "    Returns:\n",
    "        idx_tr (np.ndarray): 1D int array of train indices\n",
    "        idx_te (np.ndarray): 1D int array of test indices\n",
    "    \"\"\"\n",
    "    # ---- validate N\n",
    "    if not isinstance(N, (int, np.integer)):\n",
    "        raise TypeError(f\"N must be an int, got {type(N)}\")\n",
    "    if N <= 1:\n",
    "        raise ValueError(f\"N must be > 1, got N={N}\")\n",
    "\n",
    "    # ---- validate test_size\n",
    "    if isinstance(test_size, (int, np.integer)):\n",
    "        n_test = int(test_size)\n",
    "        if n_test <= 0 or n_test >= N:\n",
    "            raise ValueError(f\"Integer test_size must be in [1, N-1], got {test_size} for N={N}\")\n",
    "    else:\n",
    "        # float\n",
    "        ts = float(test_size)\n",
    "        if not (0.0 < ts < 1.0):\n",
    "            raise ValueError(f\"Float test_size must be in (0,1), got {test_size}\")\n",
    "        n_test = int(round(N * ts))\n",
    "        # enforce at least 1 and at most N-1\n",
    "        n_test = max(1, min(N - 1, n_test))\n",
    "\n",
    "    # ---- build dummy X just for index splitting\n",
    "    idx = np.arange(N, dtype=int)\n",
    "\n",
    "    # ---- stratify handling\n",
    "    strat = None\n",
    "    if stratify is not None:\n",
    "        strat = np.asarray(stratify)\n",
    "        if strat.shape[0] != N:\n",
    "            raise ValueError(f\"stratify must have length N={N}, got {strat.shape[0]}\")\n",
    "        # sklearn requires stratify not be all-unique when some classes too small; we don't enforce here,\n",
    "        # let train_test_split raise a helpful error if stratification is impossible.\n",
    "\n",
    "    # ---- split (returns arrays of indices)\n",
    "    idx_tr, idx_te = train_test_split(\n",
    "        idx,\n",
    "        test_size=n_test if isinstance(test_size, (int, np.integer)) else test_size,\n",
    "        random_state=seed,\n",
    "        stratify=strat\n",
    "    )\n",
    "\n",
    "    # ---- enforce numpy int arrays, sorted for stability\n",
    "    idx_tr = np.asarray(idx_tr, dtype=int)\n",
    "    idx_te = np.asarray(idx_te, dtype=int)\n",
    "\n",
    "    idx_tr.sort()\n",
    "    idx_te.sort()\n",
    "\n",
    "    # ---- sanity checks: disjoint + cover\n",
    "    if np.intersect1d(idx_tr, idx_te).size != 0:\n",
    "        raise RuntimeError(\"Train/test indices overlap (should never happen).\")\n",
    "    if idx_tr.size + idx_te.size != N:\n",
    "        raise RuntimeError(\"Train/test indices do not cover all samples (should never happen).\")\n",
    "\n",
    "    return idx_tr, idx_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e68c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "\n",
    "def slice_targets_by_idx(df_all_v, targets=(\"homo\", \"lumo\", \"gap\"), idx_tr=None, idx_te=None, as_array=False):\n",
    "    \"\"\"\n",
    "    Scheme-2: slice targets by index arrays.\n",
    "\n",
    "    Inputs:\n",
    "        df_all_v (pd.DataFrame): RDKit-valid cleaned dataframe (length N)\n",
    "        targets (list/tuple): target column names\n",
    "        idx_tr (np.ndarray): train indices (int)\n",
    "        idx_te (np.ndarray): test indices (int)\n",
    "        as_array (bool): if True return numpy arrays, else return DataFrames\n",
    "\n",
    "    Returns:\n",
    "        Ytr, Yte: DataFrame (default) or ndarray (if as_array=True)\n",
    "    \"\"\"\n",
    "    if idx_tr is None or idx_te is None:\n",
    "        raise ValueError(\"idx_tr and idx_te must be provided.\")\n",
    "\n",
    "    if not isinstance(df_all_v, pd.DataFrame):\n",
    "        raise TypeError(f\"df_all_v must be a pandas DataFrame, got {type(df_all_v)}\")\n",
    "\n",
    "    targets = list(targets)\n",
    "    missing = [t for t in targets if t not in df_all_v.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Targets not found in df_all_v: {missing}. Available: {list(df_all_v.columns)}\")\n",
    "\n",
    "    N = len(df_all_v)\n",
    "    idx_tr = np.asarray(idx_tr, dtype=int)\n",
    "    idx_te = np.asarray(idx_te, dtype=int)\n",
    "\n",
    "    if idx_tr.ndim != 1 or idx_te.ndim != 1:\n",
    "        raise ValueError(\"idx_tr and idx_te must be 1D arrays.\")\n",
    "\n",
    "    if idx_tr.size == 0 or idx_te.size == 0:\n",
    "        raise ValueError(\"idx_tr and idx_te must be non-empty.\")\n",
    "\n",
    "    if idx_tr.min() < 0 or idx_te.min() < 0 or idx_tr.max() >= N or idx_te.max() >= N:\n",
    "        raise IndexError(f\"Indices out of range for df_all_v with N={N}.\")\n",
    "\n",
    "    # slice by integer positions\n",
    "    Ytr = df_all_v.iloc[idx_tr][targets].reset_index(drop=True)\n",
    "    Yte = df_all_v.iloc[idx_te][targets].reset_index(drop=True)\n",
    "\n",
    "    if as_array:\n",
    "        return Ytr.to_numpy(dtype=float), Yte.to_numpy(dtype=float)\n",
    "    return Ytr, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c3d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "def fit_binary_feature_filter_on_train(X_all, idx_tr, zero_var=True, max_zero_frac=0.99):\n",
    "    \"\"\"\n",
    "    Scheme-2: fit a column keep-mask on TRAIN ONLY for (binary / sparse-like) features.\n",
    "\n",
    "    Inputs:\n",
    "        X_all: full feature matrix for all molecules, shape (N, P).\n",
    "               Can be np.ndarray or scipy sparse matrix.\n",
    "        idx_tr: 1D int array of train indices (positions into rows of X_all).\n",
    "        zero_var: if True, drop columns with variance == 0 on train.\n",
    "        max_zero_frac: if not None, drop columns where fraction of zeros on train > max_zero_frac.\n",
    "\n",
    "    Returns:\n",
    "        keep_mask: np.ndarray (bool) of shape (P,) indicating columns to keep.\n",
    "    \"\"\"\n",
    "    if idx_tr is None:\n",
    "        raise ValueError(\"idx_tr must be provided.\")\n",
    "    idx_tr = np.asarray(idx_tr, dtype=int)\n",
    "    if idx_tr.ndim != 1 or idx_tr.size == 0:\n",
    "        raise ValueError(\"idx_tr must be a non-empty 1D int array.\")\n",
    "\n",
    "    # --- slice train rows only\n",
    "    Xtr = X_all[idx_tr]\n",
    "\n",
    "    # --- number of features\n",
    "    P = Xtr.shape[1]\n",
    "    keep = np.ones(P, dtype=bool)\n",
    "\n",
    "    # --- (a) zero-variance on TRAIN\n",
    "    if zero_var:\n",
    "        # works for dense; for sparse, var isn't directly available\n",
    "        if hasattr(Xtr, \"toarray\") and not isinstance(Xtr, np.ndarray):\n",
    "            Xtr_dense = Xtr.toarray()\n",
    "            var = Xtr_dense.var(axis=0)\n",
    "        else:\n",
    "            var = np.asarray(Xtr).var(axis=0)\n",
    "        keep &= (var > 0)\n",
    "\n",
    "    # --- (b) too-sparse (too many zeros) on TRAIN\n",
    "    if max_zero_frac is not None:\n",
    "        # compute zero fraction robustly for dense/sparse\n",
    "        n = Xtr.shape[0]\n",
    "\n",
    "        if hasattr(Xtr, \"getnnz\") and not isinstance(Xtr, np.ndarray):\n",
    "            # sparse matrix: nnz per column => zero_frac = 1 - nnz/n\n",
    "            nnz = np.asarray(Xtr.getnnz(axis=0)).ravel()\n",
    "            zero_frac = 1.0 - (nnz / float(n))\n",
    "        else:\n",
    "            Xtr_arr = np.asarray(Xtr)\n",
    "            zero_frac = (Xtr_arr == 0).mean(axis=0)\n",
    "\n",
    "        keep &= (zero_frac <= max_zero_frac)\n",
    "\n",
    "    return keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7aee25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "def apply_mask_and_slice(X_all, idx_tr, idx_te, keep_mask):\n",
    "    \"\"\"\n",
    "    Scheme-2: apply a TRAIN-fitted column mask, then slice into train/test by indices.\n",
    "\n",
    "    Inputs:\n",
    "        X_all: full feature matrix, shape (N, P). np.ndarray or scipy sparse matrix.\n",
    "        idx_tr: 1D int array of train indices\n",
    "        idx_te: 1D int array of test indices\n",
    "        keep_mask: 1D bool array of length P (columns to keep)\n",
    "\n",
    "    Returns:\n",
    "        Xtr_f: filtered train matrix, shape (len(idx_tr), P_keep)\n",
    "        Xte_f: filtered test matrix,  shape (len(idx_te), P_keep)\n",
    "    \"\"\"\n",
    "    if idx_tr is None or idx_te is None:\n",
    "        raise ValueError(\"idx_tr and idx_te must be provided.\")\n",
    "    idx_tr = np.asarray(idx_tr, dtype=int)\n",
    "    idx_te = np.asarray(idx_te, dtype=int)\n",
    "    if idx_tr.ndim != 1 or idx_te.ndim != 1:\n",
    "        raise ValueError(\"idx_tr and idx_te must be 1D int arrays.\")\n",
    "    if idx_tr.size == 0 or idx_te.size == 0:\n",
    "        raise ValueError(\"idx_tr and idx_te must be non-empty.\")\n",
    "\n",
    "    if keep_mask is None:\n",
    "        raise ValueError(\"keep_mask must be provided.\")\n",
    "    keep_mask = np.asarray(keep_mask, dtype=bool)\n",
    "    if keep_mask.ndim != 1:\n",
    "        raise ValueError(\"keep_mask must be a 1D bool array.\")\n",
    "\n",
    "    # --- sanity: feature dimension match\n",
    "    P = X_all.shape[1]\n",
    "    if keep_mask.shape[0] != P:\n",
    "        raise ValueError(f\"keep_mask length {keep_mask.shape[0]} != n_features {P}\")\n",
    "\n",
    "    # --- slice rows first (faster for big N), then filter columns\n",
    "    Xtr = X_all[idx_tr]\n",
    "    Xte = X_all[idx_te]\n",
    "\n",
    "    # works for dense and scipy sparse\n",
    "    Xtr_f = Xtr[:, keep_mask]\n",
    "    Xte_f = Xte[:, keep_mask]\n",
    "\n",
    "    return Xtr_f, Xte_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbb49ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "def fit_desc_filter_and_scaler_on_train(\n",
    "    X_desc_raw_all,\n",
    "    idx_tr,\n",
    "    desc_names,\n",
    "    var_thresh=1e-12,\n",
    "    corr_thresh=0.95,\n",
    "):\n",
    "    \"\"\"\n",
    "    Scheme-2 (train-only fit):\n",
    "    Fit descriptor cleaning + filtering + scaling using TRAIN indices only.\n",
    "\n",
    "    Inputs:\n",
    "        X_desc_raw_all : np.ndarray, shape (N, D)  (may contain NaN/Inf)\n",
    "        idx_tr         : 1D int array of train indices\n",
    "        desc_names     : list of length D (descriptor names)\n",
    "        var_thresh     : float, drop columns with variance <= var_thresh (train only)\n",
    "        corr_thresh    : float, drop one of highly-correlated pairs with |corr| > corr_thresh (train only)\n",
    "\n",
    "    Outputs:\n",
    "        keep_idx_desc    : np.ndarray of kept column indices (into original D)\n",
    "        kept_desc_names  : list of kept names (aligned with keep_idx_desc)\n",
    "        scaler_desc      : fitted StandardScaler (fit on TRAIN, filtered cols)\n",
    "\n",
    "    Strategy for NaN/Inf (train-only):\n",
    "        - Column filtering: drop descriptor columns that contain ANY NaN/Inf in TRAIN.\n",
    "        - Row handling: keep rows (do not drop molecules); NaNs are handled by column dropping.\n",
    "          (If after column drop, TRAIN still has NaN/Inf -> raise error.)\n",
    "    \"\"\"\n",
    "    X_all = np.asarray(X_desc_raw_all, dtype=float)\n",
    "    idx_tr = np.asarray(idx_tr, dtype=int)\n",
    "\n",
    "    if X_all.ndim != 2:\n",
    "        raise ValueError(\"X_desc_raw_all must be a 2D array (N, D).\")\n",
    "    N, D = X_all.shape\n",
    "\n",
    "    if len(desc_names) != D:\n",
    "        raise ValueError(f\"desc_names length {len(desc_names)} != number of columns {D}.\")\n",
    "\n",
    "    if idx_tr.ndim != 1 or idx_tr.size == 0:\n",
    "        raise ValueError(\"idx_tr must be a non-empty 1D int array.\")\n",
    "\n",
    "    # --- TRAIN slice\n",
    "    Xtr = X_all[idx_tr, :]  # shape (n_tr, D)\n",
    "\n",
    "    # 1) train-only NaN/Inf column filtering (keep rows)\n",
    "    finite_tr = np.isfinite(Xtr)  # False for NaN/Inf\n",
    "    keep_finite_cols = finite_tr.all(axis=0)  # keep only cols fully finite in TRAIN\n",
    "\n",
    "    if keep_finite_cols.sum() == 0:\n",
    "        raise ValueError(\"All descriptor columns contain NaN/Inf in TRAIN; cannot proceed.\")\n",
    "\n",
    "    # reduce to finite cols\n",
    "    Xtr0 = Xtr[:, keep_finite_cols]\n",
    "    names0 = [n for n, k in zip(desc_names, keep_finite_cols) if k]\n",
    "    idx0 = np.where(keep_finite_cols)[0]  # mapping to original indices\n",
    "\n",
    "    # After dropping bad cols, train must be fully finite\n",
    "    if not np.isfinite(Xtr0).all():\n",
    "        raise ValueError(\"Descriptors still contain NaN/Inf in TRAIN after finite-column filtering.\")\n",
    "\n",
    "    # 2) variance filter (train)\n",
    "    variances = np.var(Xtr0, axis=0)\n",
    "    keep_var = variances > var_thresh\n",
    "\n",
    "    # fallback: if everything dropped, keep all from step 1\n",
    "    if keep_var.sum() == 0:\n",
    "        keep_idx_desc = idx0\n",
    "        kept_desc_names = names0\n",
    "        Xtr_f = Xtr0\n",
    "    else:\n",
    "        Xtr_f = Xtr0[:, keep_var]\n",
    "        kept_desc_names = [n for n, k in zip(names0, keep_var) if k]\n",
    "        keep_idx_desc = idx0[keep_var]\n",
    "\n",
    "    # 3) correlation filter (train)\n",
    "    # If 0/1 columns after var filter, correlation filtering is unnecessary\n",
    "    if Xtr_f.shape[1] >= 2:\n",
    "        df_tr = pd.DataFrame(Xtr_f, columns=kept_desc_names)\n",
    "        corr = df_tr.corr().abs()\n",
    "        upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "\n",
    "        to_drop = [col for col in upper.columns if (upper[col] > corr_thresh).any()]\n",
    "        keep_corr_names = [c for c in df_tr.columns if c not in to_drop]\n",
    "\n",
    "        if len(keep_corr_names) == 0:\n",
    "            # fallback: keep at least one column\n",
    "            keep_corr_names = [df_tr.columns[0]]\n",
    "\n",
    "        # map corr-kept names back to indices\n",
    "        name_to_idx = {n: i for i, n in enumerate(kept_desc_names)}\n",
    "        keep_corr_local_idx = np.array([name_to_idx[n] for n in keep_corr_names], dtype=int)\n",
    "\n",
    "        # apply\n",
    "        Xtr_f = Xtr_f[:, keep_corr_local_idx]\n",
    "        keep_idx_desc = keep_idx_desc[keep_corr_local_idx]\n",
    "        kept_desc_names = keep_corr_names\n",
    "\n",
    "    # 4) scaler fit (train)\n",
    "    scaler_desc = StandardScaler()\n",
    "    scaler_desc.fit(Xtr_f)\n",
    "\n",
    "    return keep_idx_desc, kept_desc_names, scaler_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7e2d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "def apply_desc_filter_and_scaler(\n",
    "    X_desc_raw_all,\n",
    "    idx_tr,\n",
    "    idx_te,\n",
    "    keep_idx_desc,\n",
    "    scaler_desc,\n",
    "):\n",
    "    \"\"\"\n",
    "    Scheme-2 (apply step):\n",
    "    Apply TRAIN-fitted descriptor column filter + TRAIN-fitted scaler to get\n",
    "    scaled descriptor matrices for train/test.\n",
    "\n",
    "    Inputs:\n",
    "        X_desc_raw_all : np.ndarray, shape (N, D) (may include NaN/Inf in dropped cols)\n",
    "        idx_tr         : 1D int array of train indices\n",
    "        idx_te         : 1D int array of test indices\n",
    "        keep_idx_desc  : 1D int array of kept descriptor column indices (into original D)\n",
    "        scaler_desc    : fitted StandardScaler (fit on TRAIN after filtering)\n",
    "\n",
    "    Outputs:\n",
    "        Xtr_desc_s : np.ndarray, shape (n_tr, d_kept)  (scaled)\n",
    "        Xte_desc_s : np.ndarray, shape (n_te, d_kept)  (scaled)\n",
    "    \"\"\"\n",
    "    X_all = np.asarray(X_desc_raw_all, dtype=float)\n",
    "    idx_tr = np.asarray(idx_tr, dtype=int)\n",
    "    idx_te = np.asarray(idx_te, dtype=int)\n",
    "    keep_idx_desc = np.asarray(keep_idx_desc, dtype=int)\n",
    "\n",
    "    if X_all.ndim != 2:\n",
    "        raise ValueError(\"X_desc_raw_all must be a 2D array (N, D).\")\n",
    "\n",
    "    if idx_tr.ndim != 1 or idx_te.ndim != 1:\n",
    "        raise ValueError(\"idx_tr and idx_te must be 1D int arrays.\")\n",
    "\n",
    "    if keep_idx_desc.ndim != 1 or keep_idx_desc.size == 0:\n",
    "        raise ValueError(\"keep_idx_desc must be a non-empty 1D int array.\")\n",
    "\n",
    "    # ---- slice rows then columns (kept cols are defined in original D space)\n",
    "    Xtr = X_all[idx_tr, :][:, keep_idx_desc]\n",
    "    Xte = X_all[idx_te, :][:, keep_idx_desc]\n",
    "\n",
    "    # ---- safety: after column filtering, train/test must be finite\n",
    "    # If not, it means keep_idx_desc was inconsistent with the fit function,\n",
    "    # or the raw matrix changed.\n",
    "    if not np.isfinite(Xtr).all():\n",
    "        bad_cols = np.where(~np.isfinite(Xtr).all(axis=0))[0]\n",
    "        raise ValueError(\n",
    "            f\"TRAIN descriptors contain NaN/Inf after applying keep_idx_desc. \"\n",
    "            f\"Bad kept-col positions (0..d_kept-1): {bad_cols.tolist()}\"\n",
    "        )\n",
    "    if not np.isfinite(Xte).all():\n",
    "        bad_cols = np.where(~np.isfinite(Xte).all(axis=0))[0]\n",
    "        raise ValueError(\n",
    "            f\"TEST descriptors contain NaN/Inf after applying keep_idx_desc. \"\n",
    "            f\"Bad kept-col positions (0..d_kept-1): {bad_cols.tolist()}\"\n",
    "        )\n",
    "\n",
    "    # ---- apply scaler (fit on train only)\n",
    "    Xtr_s = scaler_desc.transform(Xtr)  # OK even if scaler was fit on same Xtr shape\n",
    "    Xte_s = scaler_desc.transform(Xte)\n",
    "\n",
    "    return Xtr_s, Xte_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a44f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "def fit_selfies_tfidf_on_train(\n",
    "    smiles_series_all,\n",
    "    idx_tr,\n",
    "    idx_te,\n",
    "    ngram_range=(2, 5),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    # optional extra cleaning like你之前做的“zero-var / too-sparse”\n",
    "    apply_bit_filter=True,\n",
    "    max_zero_frac=0.99,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Scheme-2 (strict):\n",
    "    Fit TF-IDF vectorizer on TRAIN ONLY (idx_tr), transform train/test,\n",
    "    then (optionally) apply a train-only \"too-sparse/zero-var\" filter on the dense TF-IDF matrix.\n",
    "\n",
    "    Inputs:\n",
    "        smiles_series_all : pd.Series or list-like, length N (SMILES strings, RDKit-valid already)\n",
    "        idx_tr, idx_te    : 1D int arrays (train/test indices into smiles_series_all)\n",
    "        ngram_range       : tuple for char n-grams over SELFIES\n",
    "        min_df, max_df    : TFIDF pruning settings (fit on train only)\n",
    "        apply_bit_filter  : if True, apply train-only zero-var + max_zero_frac filter on dense TFIDF\n",
    "        max_zero_frac     : drop columns where fraction of zeros in TRAIN > max_zero_frac\n",
    "        verbose           : print shapes\n",
    "\n",
    "    Outputs:\n",
    "        Xtr_selfies_dense : np.ndarray shape (n_tr, d)\n",
    "        Xte_selfies_dense : np.ndarray shape (n_te, d)\n",
    "        selfies_vec       : fitted TfidfVectorizer\n",
    "        keep_mask_selfies : np.ndarray bool shape (d_raw,) if filtering applied, else None\n",
    "                            (mask corresponds to TF-IDF feature columns after vectorizer)\n",
    "    \"\"\"\n",
    "    # ---- prepare indices\n",
    "    idx_tr = np.asarray(idx_tr, dtype=int)\n",
    "    idx_te = np.asarray(idx_te, dtype=int)\n",
    "    if idx_tr.ndim != 1 or idx_te.ndim != 1:\n",
    "        raise ValueError(\"idx_tr and idx_te must be 1D int arrays.\")\n",
    "\n",
    "    # ---- prepare SMILES list\n",
    "    if hasattr(smiles_series_all, \"iloc\"):\n",
    "        smiles_all = smiles_series_all.astype(str).tolist()\n",
    "        get_by_idx = lambda idx: [smiles_all[i] for i in idx]\n",
    "    else:\n",
    "        smiles_all = list(smiles_series_all)\n",
    "        get_by_idx = lambda idx: [smiles_all[i] for i in idx]\n",
    "\n",
    "    smiles_tr = get_by_idx(idx_tr)\n",
    "    smiles_te = get_by_idx(idx_te)\n",
    "\n",
    "    # ---- SMILES -> SELFIES (keep alignment; failures -> \"\")\n",
    "    def _smiles_list_to_selfies(smiles_list):\n",
    "        out = []\n",
    "        for s in smiles_list:\n",
    "            try:\n",
    "                s = \"\" if s is None else str(s)\n",
    "                s = s.strip()\n",
    "                if s == \"\":\n",
    "                    out.append(\"\")\n",
    "                else:\n",
    "                    out.append(sf.encoder(s))\n",
    "            except Exception:\n",
    "                out.append(\"\")\n",
    "        return out\n",
    "\n",
    "    selfies_tr = _smiles_list_to_selfies(smiles_tr)\n",
    "    selfies_te = _smiles_list_to_selfies(smiles_te)\n",
    "\n",
    "    # ---- TFIDF (fit on TRAIN only)\n",
    "    selfies_vec = TfidfVectorizer(\n",
    "        analyzer=\"char\",\n",
    "        ngram_range=ngram_range,\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "    )\n",
    "    Xtr_sparse = selfies_vec.fit_transform(selfies_tr)\n",
    "    Xte_sparse = selfies_vec.transform(selfies_te)\n",
    "\n",
    "    # ---- drop train all-zero columns (safety; usually not needed but harmless)\n",
    "    keep_nonzero = np.asarray((Xtr_sparse != 0).sum(axis=0)).ravel() > 0\n",
    "    Xtr_sparse = Xtr_sparse[:, keep_nonzero]\n",
    "    Xte_sparse = Xte_sparse[:, keep_nonzero]\n",
    "\n",
    "    # ---- dense\n",
    "    Xtr_dense = Xtr_sparse.toarray()\n",
    "    Xte_dense = Xte_sparse.toarray()\n",
    "\n",
    "    keep_mask_selfies = None\n",
    "\n",
    "    # ---- optional: your \"train-only zero-var / too-sparse\" filter on dense TFIDF\n",
    "    if apply_bit_filter:\n",
    "        # train-only variance > 0\n",
    "        var = Xtr_dense.var(axis=0)\n",
    "        keep = var > 0\n",
    "\n",
    "        # train-only max_zero_frac\n",
    "        if max_zero_frac is not None:\n",
    "            zero_frac = (Xtr_dense == 0).mean(axis=0)\n",
    "            keep &= (zero_frac <= max_zero_frac)\n",
    "\n",
    "        keep_mask_selfies = keep\n",
    "\n",
    "        Xtr_dense = Xtr_dense[:, keep_mask_selfies]\n",
    "        Xte_dense = Xte_dense[:, keep_mask_selfies]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"SELFIES TFIDF (train-fit) shapes:\")\n",
    "        print(\"  sparse raw(after nonzero):\", Xtr_sparse.shape, Xte_sparse.shape)\n",
    "        print(\"  dense:\", Xtr_dense.shape, Xte_dense.shape)\n",
    "        if apply_bit_filter:\n",
    "            print(f\"  applied train-only bit filter: kept {int(keep_mask_selfies.sum())} / {len(keep_mask_selfies)} cols\")\n",
    "\n",
    "    return Xtr_dense, Xte_dense, selfies_vec, keep_mask_selfies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e09db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "\n",
    "def build_feature_sets_9(\n",
    "    Xtr_morgan, Xte_morgan,\n",
    "    Xtr_selfies, Xte_selfies,\n",
    "    Xtr_maccs, Xte_maccs,\n",
    "    Xtr_desc_s, Xte_desc_s,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Build 9 fusion feature sets from 4 base blocks (train/test pairs).\n",
    "\n",
    "    Inputs (all MUST be numpy arrays, already aligned to the same train/test indices):\n",
    "        - Morgan     : Xtr_morgan, Xte_morgan\n",
    "        - SELFIES    : Xtr_selfies, Xte_selfies\n",
    "        - MACCS      : Xtr_maccs, Xte_maccs\n",
    "        - Desc_s     : Xtr_desc_s, Xte_desc_s  (descriptors already filtered + scaled)\n",
    "\n",
    "    Output:\n",
    "        feature_sets: dict[str, tuple[np.ndarray, np.ndarray]]\n",
    "            name -> (Xtr, Xte) for 9 fusions\n",
    "    \"\"\"\n",
    "    # ---- basic sanity checks\n",
    "    def _check_pair(Xtr, Xte, name):\n",
    "        if not isinstance(Xtr, np.ndarray) or not isinstance(Xte, np.ndarray):\n",
    "            raise TypeError(f\"{name} must be numpy arrays. Got {type(Xtr)} / {type(Xte)}\")\n",
    "        if Xtr.ndim != 2 or Xte.ndim != 2:\n",
    "            raise ValueError(f\"{name} must be 2D arrays. Got shapes {Xtr.shape} / {Xte.shape}\")\n",
    "        if Xtr.shape[0] <= 0 or Xte.shape[0] <= 0:\n",
    "            raise ValueError(f\"{name} has empty rows: {Xtr.shape} / {Xte.shape}\")\n",
    "\n",
    "    _check_pair(Xtr_morgan,  Xte_morgan,  \"Morgan\")\n",
    "    _check_pair(Xtr_selfies, Xte_selfies, \"SELFIES\")\n",
    "    _check_pair(Xtr_maccs,   Xte_maccs,   \"MACCS\")\n",
    "    _check_pair(Xtr_desc_s,  Xte_desc_s,  \"Desc_s\")\n",
    "\n",
    "    # ---- row alignment checks (train rows must match across blocks; test rows must match across blocks)\n",
    "    ntr = Xtr_morgan.shape[0]\n",
    "    nte = Xte_morgan.shape[0]\n",
    "    for nm, Xtr, Xte in [\n",
    "        (\"SELFIES\", Xtr_selfies, Xte_selfies),\n",
    "        (\"MACCS\",   Xtr_maccs,   Xte_maccs),\n",
    "        (\"Desc_s\",  Xtr_desc_s,  Xte_desc_s),\n",
    "    ]:\n",
    "        if Xtr.shape[0] != ntr or Xte.shape[0] != nte:\n",
    "            raise ValueError(\n",
    "                f\"Row mismatch vs Morgan. Morgan train/test = {ntr}/{nte}, \"\n",
    "                f\"{nm} train/test = {Xtr.shape[0]}/{Xte.shape[0]}\"\n",
    "            )\n",
    "\n",
    "    def _hstack(parts_tr, parts_te):\n",
    "        Xtr = np.hstack(parts_tr) if len(parts_tr) > 1 else parts_tr[0]\n",
    "        Xte = np.hstack(parts_te) if len(parts_te) > 1 else parts_te[0]\n",
    "        return Xtr, Xte\n",
    "\n",
    "    feature_sets = {\n",
    "        # 1) single blocks\n",
    "        \"Morgan\": (Xtr_morgan, Xte_morgan),\n",
    "        \"SELFIES\": (Xtr_selfies, Xte_selfies),\n",
    "        \"Descriptors\": (Xtr_desc_s, Xte_desc_s),\n",
    "\n",
    "        # 2) two-way fusions\n",
    "        \"Morgan+Desc\": _hstack([Xtr_morgan, Xtr_desc_s], [Xte_morgan, Xte_desc_s]),\n",
    "        \"Morgan+SELFIES\": _hstack([Xtr_morgan, Xtr_selfies], [Xte_morgan, Xte_selfies]),\n",
    "        \"SELFIES+Desc\": _hstack([Xtr_selfies, Xtr_desc_s], [Xte_selfies, Xte_desc_s]),\n",
    "\n",
    "        # 3) three-way\n",
    "        \"Morgan+SELFIES+Desc\": _hstack(\n",
    "            [Xtr_morgan, Xtr_selfies, Xtr_desc_s],\n",
    "            [Xte_morgan, Xte_selfies, Xte_desc_s],\n",
    "        ),\n",
    "        \"Morgan+MACCS+Desc\": _hstack(\n",
    "            [Xtr_morgan, Xtr_maccs, Xtr_desc_s],\n",
    "            [Xte_morgan, Xte_maccs, Xte_desc_s],\n",
    "        ),\n",
    "\n",
    "        # 4) full\n",
    "        \"ALL (Morgan+SELFIES+MACCS+Desc)\": _hstack(\n",
    "            [Xtr_morgan, Xtr_selfies, Xtr_maccs, Xtr_desc_s],\n",
    "            [Xte_morgan, Xte_selfies, Xte_maccs, Xte_desc_s],\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Fusion feature shapes (9 sets):\")\n",
    "        for k, (Xtr, Xte) in feature_sets.items():\n",
    "            print(f\"  {k:32s} | train {Xtr.shape} | test {Xte.shape}\")\n",
    "\n",
    "    return feature_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70674c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "\n",
    "def get_model_zoo(seed=42, pca_dim=100):\n",
    "    \"\"\"\n",
    "    Return a dict of 11 models (6 tree/boosting + 5 linear/kernel/knn/gpr-style),\n",
    "    using your existing imports.\n",
    "\n",
    "    Output:\n",
    "        models: dict[str, estimator]\n",
    "            Each value is a fresh sklearn-compatible estimator (or Pipeline).\n",
    "    \"\"\"\n",
    "    SEED = int(seed)\n",
    "\n",
    "    # ---- 6 \"tree-style\" models (no scaling needed)\n",
    "    tree_models = {\n",
    "        \"RF\": RandomForestRegressor(\n",
    "            n_estimators=500,\n",
    "            random_state=SEED,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \"ExtraTrees\": ExtraTreesRegressor(\n",
    "            n_estimators=800,\n",
    "            random_state=SEED,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \"HistGB\": HistGradientBoostingRegressor(\n",
    "            random_state=SEED,\n",
    "            max_depth=None,\n",
    "            learning_rate=0.05,\n",
    "            max_iter=400\n",
    "        ),\n",
    "        \"XGB\": XGBRegressor(\n",
    "            n_estimators=800,\n",
    "            learning_rate=0.03,\n",
    "            max_depth=6,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            reg_lambda=1.0,\n",
    "            random_state=SEED,\n",
    "            n_jobs=-1,\n",
    "            tree_method=\"hist\",\n",
    "        ),\n",
    "        \"LightGBM\": LGBMRegressor(\n",
    "            n_estimators=1200,\n",
    "            learning_rate=0.03,\n",
    "            num_leaves=31,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            random_state=SEED,\n",
    "            n_jobs=-1,\n",
    "        ),\n",
    "        # linear baseline (you used this in the \"tree table\" previously)\n",
    "        \"RidgeCV\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", RidgeCV(alphas=np.logspace(-6, 6, 25)))\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    # ---- 5 \"linear/kernel/knn/gpr\" models (your earlier set, excluding MLP)\n",
    "    # Note: PCA is included for SVR/KNN/GPR for stability in high-dim.\n",
    "    linear_kernel_models = {\n",
    "        \"Lasso\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", Lasso(alpha=1e-3, max_iter=20000, random_state=SEED)),\n",
    "        ]),\n",
    "        \"ElasticNet\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", ElasticNet(alpha=1e-3, l1_ratio=0.5, max_iter=20000, random_state=SEED)),\n",
    "        ]),\n",
    "        \"SVR+PCA\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=int(pca_dim), random_state=SEED)),\n",
    "            (\"model\", SVR(C=10.0, gamma=\"scale\", epsilon=0.1)),\n",
    "        ]),\n",
    "        \"KNN+PCA\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=int(pca_dim), random_state=SEED)),\n",
    "            (\"model\", KNeighborsRegressor(n_neighbors=7, weights=\"distance\")),\n",
    "        ]),\n",
    "        \"GPR+PCA50\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=50, random_state=SEED)),\n",
    "            (\"model\", GaussianProcessRegressor(\n",
    "                kernel=C(1.0, (1e-2, 1e2)) * RBF(length_scale=1.0) + WhiteKernel(noise_level=1e-3),\n",
    "                random_state=SEED,\n",
    "                normalize_y=True\n",
    "            )),\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    # ---- merge into 11-model zoo\n",
    "    models = {}\n",
    "    models.update(tree_models)\n",
    "    models.update(linear_kernel_models)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6c24c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "def evaluate_feature_model_grid_one_seed(\n",
    "    feature_sets,\n",
    "    models,\n",
    "    Ytr,\n",
    "    Yte,\n",
    "    return_predictions=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate (feature_set × model) grid for ONE seed / ONE split.\n",
    "\n",
    "    Inputs:\n",
    "        feature_sets: dict[str, (Xtr, Xte)]\n",
    "            9 fusions (or any number). Xtr/Xte must be numpy arrays (dense).\n",
    "        models: dict[str, estimator]\n",
    "            Model zoo (e.g., 11 models). Each must support .fit(X,y) and .predict(X).\n",
    "        Ytr, Yte: pd.DataFrame or np.ndarray\n",
    "            Targets aligned to Xtr/Xte rows.\n",
    "            If DataFrame: must contain columns ['homo','lumo','gap'] (or at least these three).\n",
    "            If ndarray: assumed shape (n_samples, 3) in order [homo, lumo, gap].\n",
    "\n",
    "    Outputs:\n",
    "        df_seed_results: pd.DataFrame\n",
    "            One row per (feature, model) containing:\n",
    "              - R2/RMSE/MAE for HOMO\n",
    "              - R2/RMSE/MAE for LUMO\n",
    "              - R2/RMSE/MAE for GAP_direct\n",
    "              - R2/RMSE/MAE for GAP_derived (from LUMO_pred - HOMO_pred)\n",
    "              - Delta_GAP = R2_GAP_derived - R2_GAP_direct\n",
    "\n",
    "        If return_predictions=True:\n",
    "            returns (df_seed_results, pred_store)\n",
    "            pred_store is a dict keyed by (feature_name, model_name) -> dict of preds\n",
    "    \"\"\"\n",
    "    # ---------- helpers ----------\n",
    "    def _to_col(Y, colname, colidx):\n",
    "        if isinstance(Y, pd.DataFrame):\n",
    "            return Y[colname].to_numpy()\n",
    "        Y = np.asarray(Y)\n",
    "        return Y[:, colidx]\n",
    "\n",
    "    def _rmse(y_true, y_pred):\n",
    "        # avoid squared=False deprecation differences across sklearn versions\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        return float(np.sqrt(mse))\n",
    "\n",
    "    def _safe_clone(est):\n",
    "        # use sklearn.clone when possible; fall back to manual param copy\n",
    "        try:\n",
    "            return clone(est)\n",
    "        except Exception:\n",
    "            return est.__class__(**est.get_params())\n",
    "\n",
    "    def _safe_fit_predict(est, Xtr, ytr, Xte, seed_for_pca=42):\n",
    "        \"\"\"\n",
    "        Fit and predict, with a safety fix:\n",
    "        if Pipeline contains PCA and n_components is too large for (n_samples, n_features),\n",
    "        shrink PCA components automatically.\n",
    "        \"\"\"\n",
    "        est2 = _safe_clone(est)\n",
    "\n",
    "        if isinstance(est2, Pipeline):\n",
    "            step_names = [name for name, _ in est2.steps]\n",
    "            if \"pca\" in step_names:\n",
    "                # determine k\n",
    "                pca_step = est2.named_steps[\"pca\"]\n",
    "                k = pca_step.n_components\n",
    "                nsamp, nfeat = int(Xtr.shape[0]), int(Xtr.shape[1])\n",
    "                k2 = int(min(k, nsamp, nfeat))\n",
    "                if k2 < 1:\n",
    "                    k2 = 1\n",
    "                if k2 != k:\n",
    "                    # rebuild pipeline with adjusted PCA\n",
    "                    new_steps = []\n",
    "                    for name, step in est2.steps:\n",
    "                        if name == \"pca\":\n",
    "                            new_steps.append((\"pca\", PCA(n_components=k2, random_state=seed_for_pca)))\n",
    "                        else:\n",
    "                            new_steps.append((name, step))\n",
    "                    est2 = Pipeline(new_steps)\n",
    "\n",
    "        est2.fit(Xtr, ytr)\n",
    "        pred_tr = est2.predict(Xtr)\n",
    "        pred_te = est2.predict(Xte)\n",
    "        return pred_tr, pred_te, est2\n",
    "\n",
    "    # ---------- extract targets ----------\n",
    "    ytr_h = _to_col(Ytr, \"homo\", 0)\n",
    "    ytr_l = _to_col(Ytr, \"lumo\", 1)\n",
    "    ytr_g = _to_col(Ytr, \"gap\",  2)\n",
    "\n",
    "    yte_h = _to_col(Yte, \"homo\", 0)\n",
    "    yte_l = _to_col(Yte, \"lumo\", 1)\n",
    "    yte_g = _to_col(Yte, \"gap\",  2)\n",
    "\n",
    "    rows = []\n",
    "    pred_store = {} if return_predictions else None\n",
    "\n",
    "    # ---------- main loop ----------\n",
    "    for feat_name, (Xtr, Xte) in feature_sets.items():\n",
    "        Xtr = np.asarray(Xtr)\n",
    "        Xte = np.asarray(Xte)\n",
    "\n",
    "        for model_name, est in models.items():\n",
    "\n",
    "            # ---- HOMO\n",
    "            p_h_tr, p_h_te, est_h = _safe_fit_predict(est, Xtr, ytr_h, Xte)\n",
    "\n",
    "            # ---- LUMO\n",
    "            p_l_tr, p_l_te, est_l = _safe_fit_predict(est, Xtr, ytr_l, Xte)\n",
    "\n",
    "            # ---- GAP direct\n",
    "            p_g_tr, p_g_te, est_g = _safe_fit_predict(est, Xtr, ytr_g, Xte)\n",
    "\n",
    "            # ---- GAP derived\n",
    "            p_gd_tr = p_l_tr - p_h_tr\n",
    "            p_gd_te = p_l_te - p_h_te\n",
    "\n",
    "            # ---- metrics\n",
    "            r2_h = float(r2_score(yte_h, p_h_te))\n",
    "            r2_l = float(r2_score(yte_l, p_l_te))\n",
    "            r2_gd = float(r2_score(yte_g, p_g_te))\n",
    "            r2_gv = float(r2_score(yte_g, p_gd_te))  # derived\n",
    "\n",
    "            rmse_h = _rmse(yte_h, p_h_te)\n",
    "            rmse_l = _rmse(yte_l, p_l_te)\n",
    "            rmse_gd = _rmse(yte_g, p_g_te)\n",
    "            rmse_gv = _rmse(yte_g, p_gd_te)\n",
    "\n",
    "            mae_h = float(mean_absolute_error(yte_h, p_h_te))\n",
    "            mae_l = float(mean_absolute_error(yte_l, p_l_te))\n",
    "            mae_gd = float(mean_absolute_error(yte_g, p_g_te))\n",
    "            mae_gv = float(mean_absolute_error(yte_g, p_gd_te))\n",
    "\n",
    "            rows.append({\n",
    "                \"feature\": feat_name,\n",
    "                \"model\": model_name,\n",
    "\n",
    "                \"R2_HOMO\": r2_h,\n",
    "                \"RMSE_HOMO\": rmse_h,\n",
    "                \"MAE_HOMO\": mae_h,\n",
    "\n",
    "                \"R2_LUMO\": r2_l,\n",
    "                \"RMSE_LUMO\": rmse_l,\n",
    "                \"MAE_LUMO\": mae_l,\n",
    "\n",
    "                \"R2_GAP_direct\": r2_gd,\n",
    "                \"RMSE_GAP_direct\": rmse_gd,\n",
    "                \"MAE_GAP_direct\": mae_gd,\n",
    "\n",
    "                \"R2_GAP_derived\": r2_gv,\n",
    "                \"RMSE_GAP_derived\": rmse_gv,\n",
    "                \"MAE_GAP_derived\": mae_gv,\n",
    "\n",
    "                \"Delta_GAP\": r2_gv - r2_gd,\n",
    "            })\n",
    "\n",
    "            if return_predictions:\n",
    "                pred_store[(feat_name, model_name)] = {\n",
    "                    \"HOMO_tr\": p_h_tr, \"HOMO_te\": p_h_te,\n",
    "                    \"LUMO_tr\": p_l_tr, \"LUMO_te\": p_l_te,\n",
    "                    \"GAP_direct_tr\": p_g_tr, \"GAP_direct_te\": p_g_te,\n",
    "                    \"GAP_derived_tr\": p_gd_tr, \"GAP_derived_te\": p_gd_te,\n",
    "                }\n",
    "\n",
    "    df_seed_results = pd.DataFrame(rows)\n",
    "\n",
    "    if return_predictions:\n",
    "        return df_seed_results, pred_store\n",
    "    return df_seed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fff34832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "def run_grid_over_seeds(\n",
    "    df_all_v,\n",
    "    X_morgan_base_all,\n",
    "    X_maccs_all,\n",
    "    X_desc_raw_all,\n",
    "    desc_names,\n",
    "    seeds,\n",
    "    test_size=0.2,\n",
    "    smiles_col=\"smiles\",\n",
    "    targets=(\"homo\", \"lumo\", \"gap\"),\n",
    "    # ---- TFIDF / SELFIES params (科研严格：每个seed都fit在train)\n",
    "    ngram_range=(2, 5),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    selfies_max_zero_frac=0.99,\n",
    "    # ---- binary filters (Morgan/MACCS)\n",
    "    morgan_max_zero_frac=0.99,\n",
    "    maccs_max_zero_frac=None,  \n",
    "    # ---- descriptor filters\n",
    "    var_thresh_desc=1e-12,\n",
    "    corr_thresh_desc=0.95,\n",
    "    # ---- choose which morgan to use in fusion\n",
    "    use_morgan=\"base\",  # \"base\" or \"var\" (if you also pass X_morgan_var_all in future)\n",
    "    # ---- models\n",
    "    models=None,  # if None -> get_model_zoo()\n",
    "    # ---- verbosity\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run full grid (9 feature fusions × models × 1 seed) over multiple seeds.\n",
    "\n",
    "    Inputs:\n",
    "        df_all_v: cleaned + RDKit-valid dataframe (must include smiles_col + targets)\n",
    "        X_morgan_base_all: (N, 1024) full Morgan base matrix aligned to df_all_v\n",
    "        X_maccs_all: (N, 167) full MACCS matrix aligned to df_all_v\n",
    "        X_desc_raw_all: (N, D) raw descriptors (may include NaN) aligned to df_all_v\n",
    "        desc_names: list of descriptor names (len D)\n",
    "        seeds: list[int]\n",
    "        test_size: float\n",
    "\n",
    "    Outputs:\n",
    "        df_all_results: long table with columns:\n",
    "            seed, feature, model, (metrics columns...)\n",
    "        df_summary: aggregated mean/std by (feature, model) for each metric\n",
    "    \"\"\"\n",
    "    # ---------- basic checks ----------\n",
    "    N = len(df_all_v)\n",
    "    if X_morgan_base_all.shape[0] != N:\n",
    "        raise ValueError(f\"X_morgan_base_all rows {X_morgan_base_all.shape[0]} != N {N}\")\n",
    "    if X_maccs_all.shape[0] != N:\n",
    "        raise ValueError(f\"X_maccs_all rows {X_maccs_all.shape[0]} != N {N}\")\n",
    "    if X_desc_raw_all.shape[0] != N:\n",
    "        raise ValueError(f\"X_desc_raw_all rows {X_desc_raw_all.shape[0]} != N {N}\")\n",
    "    if isinstance(targets, tuple):\n",
    "        targets = list(targets)\n",
    "\n",
    "    # models default\n",
    "    if models is None:\n",
    "        models = get_model_zoo()\n",
    "\n",
    "    # ---------- per-seed loop ----------\n",
    "    all_seed_dfs = []\n",
    "\n",
    "    for sd in seeds:\n",
    "        if verbose:\n",
    "            print(f\"\\n=== Seed {sd} ===\")\n",
    "\n",
    "        # ---- 1) indices split (scheme-2)\n",
    "        idx_tr, idx_te = make_train_test_indices(N=N, seed=sd, test_size=test_size, stratify=None)\n",
    "\n",
    "        # ---- 2) slice targets\n",
    "        Ytr, Yte = slice_targets_by_idx(df_all_v, targets=targets, idx_tr=idx_tr, idx_te=idx_te)\n",
    "\n",
    "        # ---- 3) Morgan + MACCS: fit mask on train, apply to train/test\n",
    "        # choose morgan block\n",
    "        if use_morgan.lower() != \"base\":\n",
    "            raise ValueError(\"Currently only use_morgan='base' supported in this function signature.\")\n",
    "\n",
    "        keep_morgan = fit_binary_feature_filter_on_train(\n",
    "            X_all=X_morgan_base_all,\n",
    "            idx_tr=idx_tr,\n",
    "            zero_var=True,\n",
    "            max_zero_frac=morgan_max_zero_frac\n",
    "        )\n",
    "        Xtr_morgan, Xte_morgan = apply_mask_and_slice(\n",
    "            X_all=X_morgan_base_all,\n",
    "            idx_tr=idx_tr,\n",
    "            idx_te=idx_te,\n",
    "            keep_mask=keep_morgan\n",
    "        )\n",
    "\n",
    "        keep_maccs = fit_binary_feature_filter_on_train(\n",
    "            X_all=X_maccs_all,\n",
    "            idx_tr=idx_tr,\n",
    "            zero_var=True,\n",
    "            max_zero_frac=maccs_max_zero_frac\n",
    "        )\n",
    "        Xtr_maccs, Xte_maccs = apply_mask_and_slice(\n",
    "            X_all=X_maccs_all,\n",
    "            idx_tr=idx_tr,\n",
    "            idx_te=idx_te,\n",
    "            keep_mask=keep_maccs\n",
    "        )\n",
    "\n",
    "        # ---- 4) descriptors: fit filters+scaler on train, apply to train/test\n",
    "        keep_idx_desc, kept_desc_names, scaler_desc = fit_desc_filter_and_scaler_on_train(\n",
    "            X_desc_raw_all=X_desc_raw_all,\n",
    "            idx_tr=idx_tr,\n",
    "            desc_names=desc_names,\n",
    "            var_thresh=var_thresh_desc,\n",
    "            corr_thresh=corr_thresh_desc,\n",
    "        )\n",
    "        Xtr_desc_s, Xte_desc_s = apply_desc_filter_and_scaler(\n",
    "            X_desc_raw_all=X_desc_raw_all,\n",
    "            idx_tr=idx_tr,\n",
    "            idx_te=idx_te,\n",
    "            keep_idx_desc=keep_idx_desc,\n",
    "            scaler_desc=scaler_desc\n",
    "        )\n",
    "\n",
    "        # ---- 5) SELFIES TFIDF: fit on train only , transform test\n",
    "        Xtr_selfies_dense, Xte_selfies_dense, selfies_vec, keep_mask_selfies = fit_selfies_tfidf_on_train(\n",
    "            smiles_series=df_all_v[smiles_col],\n",
    "            idx_tr=idx_tr,\n",
    "            idx_te=idx_te,\n",
    "            ngram_range=ngram_range,\n",
    "            min_df=min_df,\n",
    "            max_df=max_df,\n",
    "            max_zero_frac=selfies_max_zero_frac\n",
    "        )\n",
    "\n",
    "        # ---- 6) 9 fusions\n",
    "        feature_sets = build_feature_sets_9(\n",
    "            Xtr_morgan=Xtr_morgan, Xte_morgan=Xte_morgan,\n",
    "            Xtr_selfies=Xtr_selfies_dense, Xte_selfies=Xte_selfies_dense,\n",
    "            Xtr_maccs=Xtr_maccs, Xte_maccs=Xte_maccs,\n",
    "            Xtr_desc_s=Xtr_desc_s, Xte_desc_s=Xte_desc_s,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # ---- 7) evaluate grid for this seed\n",
    "        df_seed = evaluate_feature_model_grid_one_seed(\n",
    "            feature_sets=feature_sets,\n",
    "            models=models,\n",
    "            Ytr=Ytr,\n",
    "            Yte=Yte,\n",
    "            return_predictions=False\n",
    "        )\n",
    "\n",
    "        # add seed column\n",
    "        df_seed.insert(0, \"seed\", sd)\n",
    "        all_seed_dfs.append(df_seed)\n",
    "\n",
    "    # ---------- concat all seeds ----------\n",
    "    df_all_results = pd.concat(all_seed_dfs, ignore_index=True)\n",
    "\n",
    "    # ---------- summary mean/std ----------\n",
    "    metric_cols = [\n",
    "        \"R2_HOMO\",\"RMSE_HOMO\",\"MAE_HOMO\",\n",
    "        \"R2_LUMO\",\"RMSE_LUMO\",\"MAE_LUMO\",\n",
    "        \"R2_GAP_direct\",\"RMSE_GAP_direct\",\"MAE_GAP_direct\",\n",
    "        \"R2_GAP_derived\",\"RMSE_GAP_derived\",\"MAE_GAP_derived\",\n",
    "        \"Delta_GAP\",\n",
    "    ]\n",
    "    present_metric_cols = [c for c in metric_cols if c in df_all_results.columns]\n",
    "\n",
    "    agg = {}\n",
    "    for c in present_metric_cols:\n",
    "        agg[c + \"_mean\"] = (c, \"mean\")\n",
    "        agg[c + \"_std\"]  = (c, \"std\")\n",
    "\n",
    "    df_summary = (\n",
    "        df_all_results\n",
    "        .groupby([\"feature\", \"model\"], as_index=False)\n",
    "        .agg(**agg)\n",
    "        .sort_values(\"R2_GAP_derived_mean\", ascending=False, ignore_index=True)\n",
    "        if \"R2_GAP_derived_mean\" in [k for k in agg.keys()]\n",
    "        else df_all_results.groupby([\"feature\",\"model\"], as_index=False).agg(**agg)\n",
    "    )\n",
    "\n",
    "    return df_all_results, df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d024b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "\n",
    "def plot_multi_seed_stability(\n",
    "    df_all_results,\n",
    "    targets=(\"HOMO\", \"LUMO\", \"GAP_direct\", \"GAP_derived\"),\n",
    "    # if True: each box = (feature, model); if False: aggregate models -> each box = feature\n",
    "    group_by_model=True,\n",
    "    # metric to visualize: \"R2\" or \"RMSE\" or \"MAE\"\n",
    "    metric=\"R2\",\n",
    "    # show top-k groups (by mean of the chosen metric) to keep plot readable\n",
    "    top_k=20,\n",
    "    # sort by mean score (descending for R2, ascending for RMSE/MAE)\n",
    "    sort_by=\"mean\",\n",
    "    figsize=(14, 4),\n",
    "    rotate_xticks=45,\n",
    "    show=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot multi-seed stability (boxplots) for 4 targets:\n",
    "      - HOMO\n",
    "      - LUMO\n",
    "      - GAP_direct (directly predicted)\n",
    "      - GAP_derived (LUMO_pred - HOMO_pred)\n",
    "\n",
    "    Input:\n",
    "        df_all_results: long table from run_grid_over_seeds()\n",
    "          must include columns: seed, feature, model and metric columns:\n",
    "            R2_HOMO, R2_LUMO, R2_GAP_direct, R2_GAP_derived\n",
    "            (or RMSE_*, MAE_* if metric != R2)\n",
    "\n",
    "    Output:\n",
    "        fig, axes, df_rank (ranking table used for plotting)\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as _np\n",
    "    import pandas as _pd\n",
    "\n",
    "    # --------- map naming ----------\n",
    "    metric = metric.upper()\n",
    "    if metric not in (\"R2\", \"RMSE\", \"MAE\"):\n",
    "        raise ValueError(\"metric must be one of: 'R2', 'RMSE', 'MAE'\")\n",
    "\n",
    "    col_map = {\n",
    "        \"HOMO\": f\"{metric}_HOMO\",\n",
    "        \"LUMO\": f\"{metric}_LUMO\",\n",
    "        \"GAP_direct\": f\"{metric}_GAP_direct\",\n",
    "        \"GAP_derived\": f\"{metric}_GAP_derived\",\n",
    "    }\n",
    "\n",
    "    missing = [col_map[t] for t in targets if col_map[t] not in df_all_results.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"df_all_results is missing required columns: {missing}\")\n",
    "\n",
    "    # --------- define grouping key ----------\n",
    "    dfp = df_all_results.copy()\n",
    "    if group_by_model:\n",
    "        dfp[\"group\"] = dfp[\"feature\"].astype(str) + \" | \" + dfp[\"model\"].astype(str)\n",
    "    else:\n",
    "        dfp[\"group\"] = dfp[\"feature\"].astype(str)\n",
    "\n",
    "    # --------- ranking to pick top_k groups ----------\n",
    "    # Decide sorting direction\n",
    "    higher_is_better = (metric == \"R2\")\n",
    "    ascending = not higher_is_better\n",
    "\n",
    "    # rank by mean score on GAP_derived by default (most relevant stability target)\n",
    "    rank_target = \"GAP_derived\" if \"GAP_derived\" in targets else targets[0]\n",
    "    score_col = col_map[rank_target]\n",
    "\n",
    "    df_rank = (\n",
    "        dfp.groupby(\"group\")[score_col]\n",
    "        .agg([\"mean\", \"std\", \"count\"])\n",
    "        .reset_index()\n",
    "        .sort_values(\"mean\", ascending=ascending)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    if top_k is not None:\n",
    "        df_rank = df_rank.head(int(top_k))\n",
    "\n",
    "    keep_groups = set(df_rank[\"group\"])\n",
    "    dfp = dfp[dfp[\"group\"].isin(keep_groups)].copy()\n",
    "\n",
    "    # keep x-order consistent with ranking\n",
    "    order = df_rank[\"group\"].tolist()\n",
    "    dfp[\"group\"] = _pd.Categorical(dfp[\"group\"], categories=order, ordered=True)\n",
    "\n",
    "    # --------- plotting (no seaborn; matplotlib only) ----------\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    n = len(targets)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize, sharey=(metric == \"R2\"))\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, t in zip(axes, targets):\n",
    "        ycol = col_map[t]\n",
    "        # collect data per group in the ranked order\n",
    "        data = [dfp.loc[dfp[\"group\"] == g, ycol].dropna().values for g in order]\n",
    "\n",
    "        ax.boxplot(\n",
    "            data,\n",
    "            vert=True,\n",
    "            patch_artist=False,\n",
    "            showmeans=True,\n",
    "            meanline=True,\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"{metric} stability: {t}\")\n",
    "        ax.set_xticks(range(1, len(order) + 1))\n",
    "        ax.set_xticklabels(order, rotation=rotate_xticks, ha=\"right\")\n",
    "\n",
    "        if metric == \"R2\":\n",
    "            ax.set_ylabel(\"R²\")\n",
    "        else:\n",
    "            ax.set_ylabel(metric)\n",
    "\n",
    "        ax.grid(True, alpha=0.2)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    return fig, axes, df_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "881ce4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESC_FUNCS len: 10\n",
      "['MolWt', 'MolLogP', 'TPSA', 'NumHDonors', 'NumHAcceptors', 'NumRotatableBonds', 'RingCount', 'NumAromaticRings', 'HeavyAtomCount', 'FractionCSP3']\n"
     ]
    }
   ],
   "source": [
    "DESC_FUNCS = [\n",
    "    (\"MolWt\", Descriptors.MolWt),\n",
    "    (\"MolLogP\", Descriptors.MolLogP),\n",
    "    (\"TPSA\", Descriptors.TPSA),\n",
    "    (\"NumHDonors\", Descriptors.NumHDonors),\n",
    "    (\"NumHAcceptors\", Descriptors.NumHAcceptors),\n",
    "    (\"NumRotatableBonds\", Descriptors.NumRotatableBonds),\n",
    "    (\"RingCount\", Descriptors.RingCount),\n",
    "    (\"NumAromaticRings\", Descriptors.NumAromaticRings),\n",
    "    (\"HeavyAtomCount\", Descriptors.HeavyAtomCount),\n",
    "    (\"FractionCSP3\", Descriptors.FractionCSP3),\n",
    "]\n",
    "csv_path = \"41597_2016_BFsdata201686_MOESM94_ESM.csv\"\n",
    "smiles_col = \"smiles\"\n",
    "targets = [\"homo\", \"lumo\", \"gap\"]\n",
    "\n",
    "print(\"DESC_FUNCS len:\", len(DESC_FUNCS))\n",
    "print([n for n, _ in DESC_FUNCS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "821d7a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 duplicate SMILES\n",
      "=== load_and_clean_csv_all ===\n",
      "CSV: 41597_2016_BFsdata201686_MOESM94_ESM.csv\n",
      "SMILES column: smiles\n",
      "Targets: ['homo', 'lumo', 'gap']\n",
      "Final molecule count: 316\n",
      "RDKit valid molecules: 316 / 316\n",
      "N (RDKit-valid molecules): 316\n",
      "FULL RDKit feature blocks (scheme-2 ALL step):\n",
      "  N molecules : 316\n",
      "  Morgan base : (316, 1024)\n",
      "  Morgan var  : (316, 2048)\n",
      "  MACCS       : (316, 167)\n",
      "  Desc(raw)   : (316, 10)\n",
      "  desc_names  : 10\n",
      "\n",
      "===== ALL feature summary =====\n",
      "df_all_v: (316, 4)\n",
      "Morgan base: (316, 1024)\n",
      "Morgan var : (316, 2048)\n",
      "MACCS      : (316, 167)\n",
      "Desc raw   : (316, 10)\n",
      "Desc names : ['MolWt', 'MolLogP', 'TPSA', 'NumHDonors', 'NumHAcceptors', 'NumRotatableBonds', 'RingCount', 'NumAromaticRings', 'HeavyAtomCount', 'FractionCSP3']\n",
      "Desc NaN rows: 0\n",
      "\n",
      "[A] ALL features built successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 1 — Scheme-2 : ALL features (run ONCE)\n",
    "\n",
    "\n",
    "# ---------- A1) load + clean csv ----------\n",
    "df_clean = load_and_clean_csv_all(\n",
    "    csv_path=csv_path,\n",
    "    smiles_col=smiles_col,\n",
    "    targets=targets,\n",
    "    drop_duplicates=True,\n",
    ")\n",
    "\n",
    "# ---------- A2) RDKit mol + valid subset ----------\n",
    "mols_all, valid_mask, df_all_v, mols_all_v = rdkit_mol_valid_mask_all(\n",
    "    df_clean,\n",
    "    smiles_col=smiles_col,\n",
    ")\n",
    "\n",
    "N = len(df_all_v)\n",
    "print(\"N (RDKit-valid molecules):\", N)\n",
    "\n",
    "# ---------- A3) RDKit feature blocks (FULL matrices) ----------\n",
    "(\n",
    "    X_morgan_base_all,\n",
    "    X_morgan_var_all,\n",
    "    X_maccs_all,\n",
    "    X_desc_raw_all,\n",
    "    desc_names,\n",
    ") = build_rdkit_feature_blocks_all(\n",
    "    mols_all_v,\n",
    "    DESC_FUNCS,\n",
    ")\n",
    "\n",
    "# ---------- sanity summary ----------\n",
    "print(\"\\n===== ALL feature summary =====\")\n",
    "print(\"df_all_v:\", df_all_v.shape)\n",
    "print(\"Morgan base:\", X_morgan_base_all.shape)\n",
    "print(\"Morgan var :\", X_morgan_var_all.shape)\n",
    "print(\"MACCS      :\", X_maccs_all.shape)\n",
    "print(\"Desc raw   :\", X_desc_raw_all.shape)\n",
    "print(\"Desc names :\", desc_names)\n",
    "\n",
    "# quick NaN check on descriptors (allowed but we report)\n",
    "print(\"Desc NaN rows:\", np.isnan(X_desc_raw_all).any(axis=1).sum())\n",
    "\n",
    "print(\"\\n[A] ALL features built successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52c5ce56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== seed 0 (1/10) =====\n",
      "\n",
      "===== seed 1 (2/10) =====\n",
      "\n",
      "===== seed 2 (3/10) =====\n",
      "\n",
      "===== seed 3 (4/10) =====\n",
      "\n",
      "===== seed 4 (5/10) =====\n",
      "\n",
      "===== seed 5 (6/10) =====\n",
      "\n",
      "===== seed 6 (7/10) =====\n",
      "\n",
      "===== seed 7 (8/10) =====\n",
      "\n",
      "===== seed 8 (9/10) =====\n",
      "\n",
      "===== seed 9 (10/10) =====\n",
      "\n",
      "[df_all_results] (990, 16) | columns: 16\n",
      "[df_summary] (99, 28)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — Scheme-2 : per-seed strict training\n",
    "#   - TFIDF is fit on TRAIN per seed \n",
    "#   - Morgan/MACCS bit filters fit on TRAIN per seed\n",
    "#   - Desc corr+scaler fit on TRAIN per seed\n",
    "\n",
    "\n",
    "# 4) make_train_test_indices\n",
    "def make_train_test_indices(N, seed=42, test_size=0.2, stratify=None):\n",
    "    \"\"\"\n",
    "    Return idx_tr / idx_te as numpy int arrays.\n",
    "    stratify: optional 1D array-like of length N (e.g., binned gap) for stratified split.\n",
    "    \"\"\"\n",
    "    idx = np.arange(N)\n",
    "    idx_tr, idx_te = train_test_split(\n",
    "        idx,\n",
    "        test_size=test_size,\n",
    "        random_state=seed,\n",
    "        stratify=stratify\n",
    "    )\n",
    "    idx_tr = np.array(idx_tr, dtype=int)\n",
    "    idx_te = np.array(idx_te, dtype=int)\n",
    "    return idx_tr, idx_te\n",
    "\n",
    "\n",
    "# 5) slice_targets_by_idx\n",
    "def slice_targets_by_idx(df_all_v, targets, idx_tr, idx_te):\n",
    "    Y = df_all_v[list(targets)].reset_index(drop=True)\n",
    "    Ytr = Y.iloc[idx_tr].reset_index(drop=True)\n",
    "    Yte = Y.iloc[idx_te].reset_index(drop=True)\n",
    "    return Ytr, Yte\n",
    "\n",
    "\n",
    "# 6) fit_binary_feature_filter_on_train\n",
    "def fit_binary_feature_filter_on_train(X_all, idx_tr, zero_var=True, max_zero_frac=0.99):\n",
    "    \"\"\"\n",
    "    Fit keep_mask on TRAIN only.\n",
    "    Works for binary/sparse-like matrices (Morgan/MACCS) and also can be used as a simple sparsity filter.\n",
    "    \"\"\"\n",
    "    Xtr = np.asarray(X_all)[idx_tr]\n",
    "    keep = np.ones(Xtr.shape[1], dtype=bool)\n",
    "\n",
    "    if zero_var:\n",
    "        var = Xtr.var(axis=0)\n",
    "        keep &= (var > 0)\n",
    "\n",
    "    if max_zero_frac is not None:\n",
    "        zero_frac = (Xtr == 0).mean(axis=0)\n",
    "        keep &= (zero_frac <= max_zero_frac)\n",
    "\n",
    "    return keep\n",
    "\n",
    "\n",
    "# 7) apply_mask_and_slice\n",
    "def apply_mask_and_slice(X_all, idx_tr, idx_te, keep_mask):\n",
    "    X_all = np.asarray(X_all)\n",
    "    Xtr = X_all[idx_tr][:, keep_mask]\n",
    "    Xte = X_all[idx_te][:, keep_mask]\n",
    "    return Xtr, Xte\n",
    "\n",
    "\n",
    "# 8) fit_desc_filter_and_scaler_on_train\n",
    "def fit_desc_filter_and_scaler_on_train(\n",
    "    X_desc_raw_all,\n",
    "    idx_tr,\n",
    "    desc_names,\n",
    "    var_thresh=1e-12,\n",
    "    corr_thresh=0.95\n",
    "):\n",
    "    \"\"\"\n",
    "    Train-only:\n",
    "      - handle NaN: drop columns that contain any NaN in TRAIN\n",
    "      - variance filter on TRAIN\n",
    "      - correlation filter on TRAIN\n",
    "      - scaler fit on TRAIN (after filters)\n",
    "    Returns keep_idx_desc (original col indices), kept_desc_names, scaler_desc\n",
    "    \"\"\"\n",
    "    X = np.asarray(X_desc_raw_all, dtype=float)\n",
    "    Xtr = X[idx_tr]\n",
    "\n",
    "    desc_names = list(desc_names)\n",
    "\n",
    "    # (0) drop columns with NaN in TRAIN\n",
    "    nan_in_col = np.isnan(Xtr).any(axis=0)\n",
    "    keep0 = ~nan_in_col\n",
    "    if keep0.sum() == 0:\n",
    "        raise ValueError(\"All descriptor columns contain NaN in TRAIN (unexpected).\")\n",
    "\n",
    "    X0 = Xtr[:, keep0]\n",
    "    names0 = [n for n, k in zip(desc_names, keep0) if k]\n",
    "    idx0 = np.where(keep0)[0]  # mapping to original\n",
    "\n",
    "    # (a) variance filter\n",
    "    var = np.var(X0, axis=0)\n",
    "    keep1 = var > var_thresh\n",
    "    if keep1.sum() == 0:\n",
    "        # fallback: keep all after NaN filter\n",
    "        keep1 = np.ones_like(keep1, dtype=bool)\n",
    "\n",
    "    X1 = X0[:, keep1]\n",
    "    names1 = [n for n, k in zip(names0, keep1) if k]\n",
    "    idx1 = idx0[np.where(keep1)[0]]  # mapping to original\n",
    "\n",
    "    # (b) correlation filter (train only)\n",
    "    df1 = pd.DataFrame(X1, columns=names1)\n",
    "    corr = df1.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    to_drop = [c for c in upper.columns if (upper[c] > corr_thresh).any()]\n",
    "    keep_cols = [c for c in df1.columns if c not in to_drop]\n",
    "\n",
    "    kept_desc_names = keep_cols\n",
    "    keep_pos = [names1.index(c) for c in kept_desc_names]\n",
    "    keep_idx_desc = idx1[np.array(keep_pos, dtype=int)]\n",
    "\n",
    "    # scaler fit on TRAIN (filtered)\n",
    "    scaler_desc = StandardScaler()\n",
    "    scaler_desc.fit(Xtr[:, keep_idx_desc])\n",
    "\n",
    "    return keep_idx_desc, kept_desc_names, scaler_desc\n",
    "\n",
    "\n",
    "# 9) apply_desc_filter_and_scaler\n",
    "def apply_desc_filter_and_scaler(X_desc_raw_all, idx_tr, idx_te, keep_idx_desc, scaler_desc):\n",
    "    X = np.asarray(X_desc_raw_all, dtype=float)\n",
    "    Xtr = X[idx_tr][:, keep_idx_desc]\n",
    "    Xte = X[idx_te][:, keep_idx_desc]\n",
    "\n",
    "    # if any NaN remains, fail (shouldn't, because we dropped NaN cols on TRAIN,\n",
    "    # but TEST could still contain NaN if that column was fine in TRAIN)\n",
    "    if np.isnan(Xtr).any() or np.isnan(Xte).any():\n",
    "        raise ValueError(\"NaN found in descriptors after applying train-fitted filters. Consider stricter NaN handling.\")\n",
    "\n",
    "    Xtr_s = scaler_desc.transform(Xtr)\n",
    "    Xte_s = scaler_desc.transform(Xte)\n",
    "    return Xtr_s, Xte_s\n",
    "\n",
    "\n",
    "# 10) fit_selfies_tfidf_on_train  (STRICT)\n",
    "def fit_selfies_tfidf_on_train(\n",
    "    smiles_series,\n",
    "    idx_tr,\n",
    "    idx_te,\n",
    "    ngram_range=(2, 5),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    max_zero_frac=0.99\n",
    "):\n",
    "    \"\"\"\n",
    "    STRICT: TFIDF is fit on TRAIN only (per seed).\n",
    "    Returns dense matrices for train/test, vectorizer, and optional keep_mask_selfies\n",
    "    (train-only sparsity filter on dense).\n",
    "    \"\"\"\n",
    "    smiles = smiles_series.reset_index(drop=True).astype(str).tolist()\n",
    "\n",
    "    def _smiles_to_selfies(s):\n",
    "        try:\n",
    "            return sf.encoder(s)\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "    train_text = [_smiles_to_selfies(smiles[i]) for i in idx_tr]\n",
    "    test_text  = [_smiles_to_selfies(smiles[i]) for i in idx_te]\n",
    "\n",
    "    vec = TfidfVectorizer(\n",
    "        analyzer=\"char\",\n",
    "        ngram_range=ngram_range,\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "    )\n",
    "\n",
    "    Xtr_sp = vec.fit_transform(train_text)\n",
    "    Xte_sp = vec.transform(test_text)\n",
    "\n",
    "    # safety: drop all-zero cols (train-only)\n",
    "    keep0 = np.asarray((Xtr_sp != 0).sum(axis=0)).ravel() > 0\n",
    "    Xtr_sp = Xtr_sp[:, keep0]\n",
    "    Xte_sp = Xte_sp[:, keep0]\n",
    "\n",
    "    Xtr = Xtr_sp.toarray()\n",
    "    Xte = Xte_sp.toarray()\n",
    "\n",
    "    # optional extra sparsity filter (train-only) on dense\n",
    "    keep_mask = fit_binary_feature_filter_on_train(Xtr, np.arange(Xtr.shape[0]), zero_var=True, max_zero_frac=max_zero_frac)\n",
    "    Xtr = Xtr[:, keep_mask]\n",
    "    Xte = Xte[:, keep_mask]\n",
    "\n",
    "    return Xtr, Xte, vec, keep_mask\n",
    "\n",
    "\n",
    "# 11) build_feature_sets_9\n",
    "def build_feature_sets_9(\n",
    "    Xtr_morgan, Xte_morgan,\n",
    "    Xtr_selfies, Xte_selfies,\n",
    "    Xtr_maccs, Xte_maccs,\n",
    "    Xtr_desc_s, Xte_desc_s,\n",
    "):\n",
    "    def _hstack(parts_tr, parts_te):\n",
    "        Xtr = np.hstack(parts_tr) if len(parts_tr) > 1 else parts_tr[0]\n",
    "        Xte = np.hstack(parts_te) if len(parts_te) > 1 else parts_te[0]\n",
    "        return Xtr, Xte\n",
    "\n",
    "    feature_sets = {\n",
    "        \"Morgan\": (Xtr_morgan, Xte_morgan),\n",
    "        \"SELFIES\": (Xtr_selfies, Xte_selfies),\n",
    "        \"Descriptors\": (Xtr_desc_s, Xte_desc_s),\n",
    "\n",
    "        \"Morgan+Desc\": _hstack([Xtr_morgan, Xtr_desc_s], [Xte_morgan, Xte_desc_s]),\n",
    "        \"Morgan+SELFIES\": _hstack([Xtr_morgan, Xtr_selfies], [Xte_morgan, Xte_selfies]),\n",
    "        \"SELFIES+Desc\": _hstack([Xtr_selfies, Xtr_desc_s], [Xte_selfies, Xte_desc_s]),\n",
    "\n",
    "        \"Morgan+SELFIES+Desc\": _hstack(\n",
    "            [Xtr_morgan, Xtr_selfies, Xtr_desc_s],\n",
    "            [Xte_morgan, Xte_selfies, Xte_desc_s],\n",
    "        ),\n",
    "\n",
    "        \"Morgan+MACCS+Desc\": _hstack(\n",
    "            [Xtr_morgan, Xtr_maccs, Xtr_desc_s],\n",
    "            [Xte_morgan, Xte_maccs, Xte_desc_s],\n",
    "        ),\n",
    "\n",
    "        \"ALL (Morgan+SELFIES+MACCS+Desc)\": _hstack(\n",
    "            [Xtr_morgan, Xtr_selfies, Xtr_maccs, Xtr_desc_s],\n",
    "            [Xte_morgan, Xte_selfies, Xte_maccs, Xte_desc_s],\n",
    "        ),\n",
    "    }\n",
    "    return feature_sets\n",
    "\n",
    "\n",
    "# 12) get_model_zoo (11 models)\n",
    "def get_model_zoo(seed=42, pca_dim=100):\n",
    "    models = {\n",
    "        # ---- trees / boosting\n",
    "        \"RF\": RandomForestRegressor(n_estimators=500, random_state=seed, n_jobs=-1),\n",
    "        \"ExtraTrees\": ExtraTreesRegressor(n_estimators=500, random_state=seed, n_jobs=-1),\n",
    "        \"HistGB\": HistGradientBoostingRegressor(random_state=seed),\n",
    "        \"XGB\": XGBRegressor(\n",
    "            n_estimators=800, max_depth=6, learning_rate=0.05,\n",
    "            subsample=0.9, colsample_bytree=0.9,\n",
    "            reg_lambda=1.0, random_state=seed, n_jobs=-1,\n",
    "            verbosity=0\n",
    "        ),\n",
    "        \"LightGBM\": LGBMRegressor(\n",
    "            n_estimators=800, learning_rate=0.05,\n",
    "            subsample=0.9, colsample_bytree=0.9,\n",
    "            random_state=seed, n_jobs=-1,\n",
    "            verbose=-1\n",
    "        ),\n",
    "\n",
    "        # ---- linear\n",
    "        \"RidgeCV\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", RidgeCV(alphas=np.logspace(-6, 6, 25))),\n",
    "        ]),\n",
    "        \"Lasso\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", Lasso(alpha=1e-3, max_iter=20000, random_state=seed)),\n",
    "        ]),\n",
    "        \"ElasticNet\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", ElasticNet(alpha=1e-3, l1_ratio=0.5, max_iter=20000, random_state=seed)),\n",
    "        ]),\n",
    "\n",
    "        # ---- kernel / neighbors / gpr\n",
    "        \"SVR+PCA\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=pca_dim, random_state=seed)),\n",
    "            (\"model\", SVR(C=10.0, gamma=\"scale\", epsilon=0.1)),\n",
    "        ]),\n",
    "        \"KNN+PCA\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=pca_dim, random_state=seed)),\n",
    "            (\"model\", KNeighborsRegressor(n_neighbors=7, weights=\"distance\")),\n",
    "        ]),\n",
    "        \"GPR+PCA50\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"pca\", PCA(n_components=50, random_state=seed)),\n",
    "            (\"model\", GaussianProcessRegressor(\n",
    "                kernel=C(1.0, (1e-2, 1e2)) * RBF(length_scale=1.0) + WhiteKernel(noise_level=1e-3),\n",
    "                random_state=seed,\n",
    "                normalize_y=True,\n",
    "            )),\n",
    "        ]),\n",
    "    }\n",
    "    return models\n",
    "\n",
    "\n",
    "# helper: safe fit/predict for PCA dims\n",
    "def _safe_fit_predict(est, Xtr, ytr, Xte, seed=42):\n",
    "    est2 = clone(est)\n",
    "    # if pipeline has PCA, make sure n_components <= min(n_samples, n_features)\n",
    "    if hasattr(est2, \"named_steps\") and \"pca\" in est2.named_steps:\n",
    "        k = est2.named_steps[\"pca\"].n_components\n",
    "        k2 = int(min(k, Xtr.shape[0], Xtr.shape[1]))\n",
    "        if k2 < 1:\n",
    "            k2 = 1\n",
    "        if k2 != k:\n",
    "            steps = []\n",
    "            for name, step in est2.steps:\n",
    "                if name == \"pca\":\n",
    "                    steps.append((\"pca\", PCA(n_components=k2, random_state=seed)))\n",
    "                else:\n",
    "                    steps.append((name, step))\n",
    "            est2 = Pipeline(steps)\n",
    "    est2.fit(Xtr, ytr)\n",
    "    pte = est2.predict(Xte)\n",
    "    ptr = est2.predict(Xtr)\n",
    "    return ptr, pte\n",
    "\n",
    "\n",
    "def _metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"RMSE\": mean_squared_error(y_true, y_pred, squared=False),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "\n",
    "# 13) evaluate_feature_model_grid_one_seed\n",
    "def evaluate_feature_model_grid_one_seed(feature_sets, models, Ytr, Yte, seed=42):\n",
    "    rows = []\n",
    "    ytr_h = Ytr[\"homo\"].values\n",
    "    ytr_l = Ytr[\"lumo\"].values\n",
    "    ytr_g = Ytr[\"gap\"].values\n",
    "\n",
    "    yte_h = Yte[\"homo\"].values\n",
    "    yte_l = Yte[\"lumo\"].values\n",
    "    yte_g = Yte[\"gap\"].values\n",
    "\n",
    "    for feat_name, (Xtr, Xte) in feature_sets.items():\n",
    "        for model_name, est in models.items():\n",
    "            # homo\n",
    "            ph_tr, ph_te = _safe_fit_predict(est, Xtr, ytr_h, Xte, seed=seed)\n",
    "            # lumo\n",
    "            pl_tr, pl_te = _safe_fit_predict(est, Xtr, ytr_l, Xte, seed=seed)\n",
    "            # gap direct\n",
    "            pg_tr, pg_te = _safe_fit_predict(est, Xtr, ytr_g, Xte, seed=seed)\n",
    "            # gap derived\n",
    "            pgd_te = pl_te - ph_te\n",
    "\n",
    "            mh = _metrics(yte_h, ph_te)\n",
    "            ml = _metrics(yte_l, pl_te)\n",
    "            mg = _metrics(yte_g, pg_te)\n",
    "            mgd = _metrics(yte_g, pgd_te)\n",
    "\n",
    "            rows.append({\n",
    "                \"feature\": feat_name,\n",
    "                \"model\": model_name,\n",
    "\n",
    "                \"R2_HOMO\": mh[\"R2\"], \"RMSE_HOMO\": mh[\"RMSE\"], \"MAE_HOMO\": mh[\"MAE\"],\n",
    "                \"R2_LUMO\": ml[\"R2\"], \"RMSE_LUMO\": ml[\"RMSE\"], \"MAE_LUMO\": ml[\"MAE\"],\n",
    "                \"R2_GAP_direct\": mg[\"R2\"], \"RMSE_GAP_direct\": mg[\"RMSE\"], \"MAE_GAP_direct\": mg[\"MAE\"],\n",
    "                \"R2_GAP_derived\": mgd[\"R2\"], \"RMSE_GAP_derived\": mgd[\"RMSE\"], \"MAE_GAP_derived\": mgd[\"MAE\"],\n",
    "                \"Delta_GAP\": mgd[\"R2\"] - mg[\"R2\"],\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "# 14) run_grid_over_seeds\n",
    "\n",
    "def run_grid_over_seeds(\n",
    "    df_all_v,\n",
    "    smiles_col,\n",
    "    targets,\n",
    "    X_morgan_base_all,\n",
    "    X_maccs_all,\n",
    "    X_desc_raw_all,\n",
    "    desc_names,\n",
    "    seeds,\n",
    "    test_size=0.2,\n",
    "    pca_dim=100,\n",
    "    max_zero_frac=0.99,\n",
    "    var_thresh=1e-12,\n",
    "    corr_thresh=0.95,\n",
    "    verbose_every=1\n",
    "):\n",
    "    N = len(df_all_v)\n",
    "    all_rows = []\n",
    "\n",
    "    for i, sd in enumerate(seeds):\n",
    "        if verbose_every and (i % verbose_every == 0):\n",
    "            print(f\"\\n===== seed {sd} ({i+1}/{len(seeds)}) =====\")\n",
    "\n",
    "        idx_tr, idx_te = make_train_test_indices(N, seed=sd, test_size=test_size)\n",
    "        Ytr, Yte = slice_targets_by_idx(df_all_v, targets, idx_tr, idx_te)\n",
    "\n",
    "        # ---- Morgan (train-only bit filter)\n",
    "        keep_m = fit_binary_feature_filter_on_train(X_morgan_base_all, idx_tr, zero_var=True, max_zero_frac=max_zero_frac)\n",
    "        Xtr_m, Xte_m = apply_mask_and_slice(X_morgan_base_all, idx_tr, idx_te, keep_m)\n",
    "\n",
    "        # ---- MACCS (train-only bit filter)\n",
    "        keep_mac = fit_binary_feature_filter_on_train(X_maccs_all, idx_tr, zero_var=True, max_zero_frac=max_zero_frac)\n",
    "        Xtr_mac, Xte_mac = apply_mask_and_slice(X_maccs_all, idx_tr, idx_te, keep_mac)\n",
    "\n",
    "        # ---- Descriptors (train-only corr+scaler)\n",
    "        keep_idx_desc, kept_desc_names, scaler_desc = fit_desc_filter_and_scaler_on_train(\n",
    "            X_desc_raw_all, idx_tr, desc_names, var_thresh=var_thresh, corr_thresh=corr_thresh\n",
    "        )\n",
    "        Xtr_desc_s, Xte_desc_s = apply_desc_filter_and_scaler(\n",
    "            X_desc_raw_all, idx_tr, idx_te, keep_idx_desc, scaler_desc\n",
    "        )\n",
    "\n",
    "        # ---- SELFIES TFIDF (STRICT per-seed train-fit)\n",
    "        Xtr_self, Xte_self, vec_self, keep_self = fit_selfies_tfidf_on_train(\n",
    "            df_all_v[smiles_col], idx_tr, idx_te,\n",
    "            ngram_range=(2, 5), min_df=2, max_df=0.95,\n",
    "            max_zero_frac=max_zero_frac\n",
    "        )\n",
    "\n",
    "        # ---- 9 fusion sets\n",
    "        feature_sets = build_feature_sets_9(\n",
    "            Xtr_m, Xte_m,\n",
    "            Xtr_self, Xte_self,\n",
    "            Xtr_mac, Xte_mac,\n",
    "            Xtr_desc_s, Xte_desc_s,\n",
    "        )\n",
    "\n",
    "        # ---- model zoo\n",
    "        models = get_model_zoo(seed=sd, pca_dim=pca_dim)\n",
    "\n",
    "        # ---- evaluate\n",
    "        df_seed = evaluate_feature_model_grid_one_seed(feature_sets, models, Ytr, Yte, seed=sd)\n",
    "        df_seed.insert(0, \"seed\", sd)\n",
    "        all_rows.append(df_seed)\n",
    "\n",
    "    df_all_results = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "    # summary mean/std per feature×model\n",
    "    metric_cols = [c for c in df_all_results.columns if c not in (\"seed\", \"feature\", \"model\")]\n",
    "    agg = {}\n",
    "    for c in metric_cols:\n",
    "        agg[c+\"_mean\"] = (c, \"mean\")\n",
    "        agg[c+\"_std\"]  = (c, \"std\")\n",
    "\n",
    "    df_summary = (\n",
    "        df_all_results\n",
    "        .groupby([\"feature\", \"model\"], as_index=False)\n",
    "        .agg(**agg)\n",
    "    )\n",
    "\n",
    "    return df_all_results, df_summary\n",
    "\n",
    "\n",
    "\n",
    "# 15) plot multi-seed stability (per feature, best model per seed)\n",
    "\n",
    "def plot_feature_stability_boxplots(df_all_results, targets=(\"HOMO\",\"LUMO\",\"GAP_direct\",\"GAP_derived\")):\n",
    "    \"\"\"\n",
    "    For each target, we take per (seed, feature) the BEST model R2, then show boxplots over seeds.\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        \"HOMO\": \"R2_HOMO\",\n",
    "        \"LUMO\": \"R2_LUMO\",\n",
    "        \"GAP_direct\": \"R2_GAP_direct\",\n",
    "        \"GAP_derived\": \"R2_GAP_derived\",\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4), sharey=False)\n",
    "    for ax, t in zip(axes, targets):\n",
    "        col = mapping[t]\n",
    "        df_best = (\n",
    "            df_all_results\n",
    "            .groupby([\"seed\", \"feature\"], as_index=False)[col]\n",
    "            .max()\n",
    "        )\n",
    "\n",
    "        features = sorted(df_best[\"feature\"].unique().tolist())\n",
    "        data = [df_best.loc[df_best[\"feature\"]==f, col].values for f in features]\n",
    "\n",
    "        ax.boxplot(data, labels=features, showmeans=True)\n",
    "        ax.set_title(f\"Stability: {t} (best model per seed)\")\n",
    "        ax.set_ylabel(\"R²\")\n",
    "        ax.tick_params(axis=\"x\", rotation=60)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# RUN (edit seeds here)\n",
    "\n",
    "seeds = list(range(10))   \n",
    "\n",
    "df_all_results, df_summary = run_grid_over_seeds(\n",
    "    df_all_v=df_all_v,\n",
    "    smiles_col=smiles_col,\n",
    "    targets=targets,\n",
    "    X_morgan_base_all=X_morgan_base_all,\n",
    "    X_maccs_all=X_maccs_all,\n",
    "    X_desc_raw_all=X_desc_raw_all,\n",
    "    desc_names=desc_names,\n",
    "    seeds=seeds,\n",
    "    test_size=0.2,\n",
    "    pca_dim=100,\n",
    "    max_zero_frac=0.99,\n",
    "    var_thresh=1e-12,\n",
    "    corr_thresh=0.95,\n",
    "    verbose_every=1\n",
    ")\n",
    "\n",
    "print(\"\\n[df_all_results]\", df_all_results.shape, \"| columns:\", len(df_all_results.columns))\n",
    "print(\"[df_summary]\", df_summary.shape)\n",
    "\n",
    "# 4 panels stability boxplots\n",
    "# I close the report here and only pick top 3 result later\n",
    "# This line also can be use \n",
    "\n",
    "# plot_feature_stability_boxplots(df_all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dff2dd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_homo_rank shape: (99, 4)\n",
      "df_lumo_rank shape: (99, 4)\n",
      "Top HOMO:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>model</th>\n",
       "      <th>R2_HOMO_mean</th>\n",
       "      <th>R2_HOMO_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morgan+Desc</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>0.724381</td>\n",
       "      <td>0.072163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morgan+MACCS+Desc</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>0.716720</td>\n",
       "      <td>0.067110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALL (Morgan+SELFIES+MACCS+Desc)</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.716181</td>\n",
       "      <td>0.078934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature       model  R2_HOMO_mean  R2_HOMO_std\n",
       "0                      Morgan+Desc  ExtraTrees      0.724381     0.072163\n",
       "1                Morgan+MACCS+Desc  ExtraTrees      0.716720     0.067110\n",
       "2  ALL (Morgan+SELFIES+MACCS+Desc)     RidgeCV      0.716181     0.078934"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top LUMO:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>model</th>\n",
       "      <th>R2_LUMO_mean</th>\n",
       "      <th>R2_LUMO_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morgan+Desc</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.742787</td>\n",
       "      <td>0.076318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morgan+MACCS+Desc</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.721238</td>\n",
       "      <td>0.081308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALL (Morgan+SELFIES+MACCS+Desc)</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.067562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature     model  R2_LUMO_mean  R2_LUMO_std\n",
       "0                      Morgan+Desc  LightGBM      0.742787     0.076318\n",
       "1                Morgan+MACCS+Desc  LightGBM      0.721238     0.081308\n",
       "2  ALL (Morgan+SELFIES+MACCS+Desc)   RidgeCV      0.718750     0.067562"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rank tables from df_summary (mean across seeds)\n",
    "df_homo_rank = (\n",
    "    df_summary[[\"feature\", \"model\", \"R2_HOMO_mean\", \"R2_HOMO_std\"]]\n",
    "    .sort_values([\"R2_HOMO_mean\", \"R2_HOMO_std\"], ascending=[False, True])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_lumo_rank = (\n",
    "    df_summary[[\"feature\", \"model\", \"R2_LUMO_mean\", \"R2_LUMO_std\"]]\n",
    "    .sort_values([\"R2_LUMO_mean\", \"R2_LUMO_std\"], ascending=[False, True])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"df_homo_rank shape:\", df_homo_rank.shape)\n",
    "print(\"df_lumo_rank shape:\", df_lumo_rank.shape)\n",
    "\n",
    "K = 3\n",
    "\n",
    "top_lumo = df_lumo_rank.head(K).reset_index(drop=True)\n",
    "top_homo = df_homo_rank.head(K).reset_index(drop=True)\n",
    "\n",
    "print(\"Top HOMO:\")\n",
    "display(top_homo)\n",
    "\n",
    "print(\"Top LUMO:\")\n",
    "display(top_lumo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f225da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOMO_feature</th>\n",
       "      <th>HOMO_model</th>\n",
       "      <th>LUMO_feature</th>\n",
       "      <th>LUMO_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morgan+Desc</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>Morgan+Desc</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morgan+Desc</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>Morgan+MACCS+Desc</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morgan+Desc</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>ALL (Morgan+SELFIES+MACCS+Desc)</td>\n",
       "      <td>RidgeCV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morgan+MACCS+Desc</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>Morgan+Desc</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morgan+MACCS+Desc</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>Morgan+MACCS+Desc</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morgan+MACCS+Desc</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>ALL (Morgan+SELFIES+MACCS+Desc)</td>\n",
       "      <td>RidgeCV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ALL (Morgan+SELFIES+MACCS+Desc)</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>Morgan+Desc</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ALL (Morgan+SELFIES+MACCS+Desc)</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>Morgan+MACCS+Desc</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ALL (Morgan+SELFIES+MACCS+Desc)</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>ALL (Morgan+SELFIES+MACCS+Desc)</td>\n",
       "      <td>RidgeCV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      HOMO_feature  HOMO_model  \\\n",
       "0                      Morgan+Desc  ExtraTrees   \n",
       "1                      Morgan+Desc  ExtraTrees   \n",
       "2                      Morgan+Desc  ExtraTrees   \n",
       "3                Morgan+MACCS+Desc  ExtraTrees   \n",
       "4                Morgan+MACCS+Desc  ExtraTrees   \n",
       "5                Morgan+MACCS+Desc  ExtraTrees   \n",
       "6  ALL (Morgan+SELFIES+MACCS+Desc)     RidgeCV   \n",
       "7  ALL (Morgan+SELFIES+MACCS+Desc)     RidgeCV   \n",
       "8  ALL (Morgan+SELFIES+MACCS+Desc)     RidgeCV   \n",
       "\n",
       "                      LUMO_feature LUMO_model  \n",
       "0                      Morgan+Desc   LightGBM  \n",
       "1                Morgan+MACCS+Desc   LightGBM  \n",
       "2  ALL (Morgan+SELFIES+MACCS+Desc)    RidgeCV  \n",
       "3                      Morgan+Desc   LightGBM  \n",
       "4                Morgan+MACCS+Desc   LightGBM  \n",
       "5  ALL (Morgan+SELFIES+MACCS+Desc)    RidgeCV  \n",
       "6                      Morgan+Desc   LightGBM  \n",
       "7                Morgan+MACCS+Desc   LightGBM  \n",
       "8  ALL (Morgan+SELFIES+MACCS+Desc)    RidgeCV  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = []\n",
    "\n",
    "for i, h in top_homo.iterrows():\n",
    "    for j, l in top_lumo.iterrows():\n",
    "        pairs.append({\n",
    "            \"HOMO_feature\": h[\"feature\"],\n",
    "            \"HOMO_model\": h[\"model\"],\n",
    "            \"LUMO_feature\": l[\"feature\"],\n",
    "            \"LUMO_model\": l[\"model\"],\n",
    "        })\n",
    "\n",
    "df_pairs = pd.DataFrame(pairs)\n",
    "print(\"Total pairs:\", len(df_pairs))\n",
    "df_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e412797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: ['RF', 'ExtraTrees', 'HistGB', 'XGB', 'LightGBM', 'RidgeCV', 'Lasso', 'ElasticNet', 'SVR+PCA', 'KNN+PCA', 'GPR+PCA50']\n"
     ]
    }
   ],
   "source": [
    "# build model zoo once\n",
    "model_map = get_model_zoo()\n",
    "\n",
    "print(\"Available models:\", list(model_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9229c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for pid, row in df_pairs.iterrows():\n",
    "\n",
    "    for sd in seeds:\n",
    "\n",
    "        # ===== split indices\n",
    "        idx_tr, idx_te = make_train_test_indices(len(df_all_v), seed=sd)\n",
    "\n",
    "        # ===== targets\n",
    "        ytr_h = df_all_v.loc[idx_tr, \"homo\"].values\n",
    "        yte_h = df_all_v.loc[idx_te, \"homo\"].values\n",
    "        ytr_l = df_all_v.loc[idx_tr, \"lumo\"].values\n",
    "        yte_l = df_all_v.loc[idx_te, \"lumo\"].values\n",
    "        ytr_g = df_all_v.loc[idx_tr, \"gap\"].values\n",
    "        yte_g = df_all_v.loc[idx_te, \"gap\"].values\n",
    "\n",
    "        # ===== Morgan\n",
    "        keep_morgan = fit_binary_feature_filter_on_train(X_morgan_base_all, idx_tr)\n",
    "        Xtr_morgan, Xte_morgan = apply_mask_and_slice(X_morgan_base_all, idx_tr, idx_te, keep_morgan)\n",
    "\n",
    "        # ===== MACCS\n",
    "        keep_maccs = fit_binary_feature_filter_on_train(X_maccs_all, idx_tr)\n",
    "        Xtr_maccs, Xte_maccs = apply_mask_and_slice(X_maccs_all, idx_tr, idx_te, keep_maccs)\n",
    "\n",
    "        # ===== descriptors\n",
    "        keep_idx_desc, kept_desc_names, scaler_desc = fit_desc_filter_and_scaler_on_train(\n",
    "            X_desc_raw_all, idx_tr, desc_names\n",
    "        )\n",
    "        Xtr_desc_s, Xte_desc_s = apply_desc_filter_and_scaler(\n",
    "            X_desc_raw_all, idx_tr, idx_te, keep_idx_desc, scaler_desc\n",
    "        )\n",
    "\n",
    "        # ===== SELFIES (per-seed TFIDF)\n",
    "        Xtr_selfies, Xte_selfies, _, _ = fit_selfies_tfidf_on_train(\n",
    "            df_all_v[\"smiles\"], idx_tr, idx_te\n",
    "        )\n",
    "\n",
    "        # ===== build 9 fusion sets\n",
    "        feature_sets = build_feature_sets_9(\n",
    "            Xtr_morgan, Xte_morgan,\n",
    "            Xtr_selfies, Xte_selfies,\n",
    "            Xtr_maccs, Xte_maccs,\n",
    "            Xtr_desc_s, Xte_desc_s,\n",
    "        )\n",
    "\n",
    "        # ===== pick requested combo\n",
    "        Xh_tr, Xh_te = feature_sets[row[\"HOMO_feature\"]]\n",
    "        Xl_tr, Xl_te = feature_sets[row[\"LUMO_feature\"]]\n",
    "\n",
    "        mh = clone(model_map[row[\"HOMO_model\"]])\n",
    "        ml = clone(model_map[row[\"LUMO_model\"]])\n",
    "\n",
    "        mh.fit(Xh_tr, ytr_h)\n",
    "        ml.fit(Xl_tr, ytr_l)\n",
    "\n",
    "        ph = mh.predict(Xh_te)\n",
    "        pl = ml.predict(Xl_te)\n",
    "\n",
    "        gap_pred = pl - ph\n",
    "\n",
    "        records.append({\n",
    "            \"pair\": pid,\n",
    "            \"seed\": sd,\n",
    "            \"HOMO\": f'{row[\"HOMO_model\"]}+{row[\"HOMO_feature\"]}',\n",
    "            \"LUMO\": f'{row[\"LUMO_model\"]}+{row[\"LUMO_feature\"]}',\n",
    "            \"R2\": r2_score(yte_g, gap_pred),\n",
    "            \"RMSE\": mean_squared_error(yte_g, gap_pred, squared=False),\n",
    "            \"MAE\": mean_absolute_error(yte_g, gap_pred),\n",
    "        })\n",
    "\n",
    "df_gap_combo = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e83404af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>R2_HOMO_mean</th>\n",
       "      <th>R2_HOMO_std</th>\n",
       "      <th>R2_HOMO_min</th>\n",
       "      <th>R2_HOMO_max</th>\n",
       "      <th>R2_LUMO_mean</th>\n",
       "      <th>R2_LUMO_std</th>\n",
       "      <th>R2_LUMO_min</th>\n",
       "      <th>R2_LUMO_max</th>\n",
       "      <th>R2_GAP_direct_mean</th>\n",
       "      <th>R2_GAP_direct_std</th>\n",
       "      <th>R2_GAP_direct_min</th>\n",
       "      <th>R2_GAP_direct_max</th>\n",
       "      <th>R2_GAP_derived_mean</th>\n",
       "      <th>R2_GAP_derived_std</th>\n",
       "      <th>R2_GAP_derived_min</th>\n",
       "      <th>R2_GAP_derived_max</th>\n",
       "      <th>model</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RidgeCV + Morgan+MACCS+Desc</td>\n",
       "      <td>0.682863</td>\n",
       "      <td>0.094272</td>\n",
       "      <td>0.491635</td>\n",
       "      <td>0.781351</td>\n",
       "      <td>0.715977</td>\n",
       "      <td>0.069319</td>\n",
       "      <td>0.603891</td>\n",
       "      <td>0.803979</td>\n",
       "      <td>0.760879</td>\n",
       "      <td>0.073729</td>\n",
       "      <td>0.649388</td>\n",
       "      <td>0.861380</td>\n",
       "      <td>0.755414</td>\n",
       "      <td>0.069041</td>\n",
       "      <td>0.649388</td>\n",
       "      <td>0.847580</td>\n",
       "      <td>RidgeCV + Morgan+MACCS+Desc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB + Morgan+MACCS+Desc</td>\n",
       "      <td>0.708732</td>\n",
       "      <td>0.091160</td>\n",
       "      <td>0.529031</td>\n",
       "      <td>0.819487</td>\n",
       "      <td>0.712974</td>\n",
       "      <td>0.055788</td>\n",
       "      <td>0.616498</td>\n",
       "      <td>0.810830</td>\n",
       "      <td>0.748114</td>\n",
       "      <td>0.144656</td>\n",
       "      <td>0.403224</td>\n",
       "      <td>0.866291</td>\n",
       "      <td>0.741622</td>\n",
       "      <td>0.120403</td>\n",
       "      <td>0.428436</td>\n",
       "      <td>0.844421</td>\n",
       "      <td>XGB + Morgan+MACCS+Desc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB + Morgan+Desc</td>\n",
       "      <td>0.702562</td>\n",
       "      <td>0.107518</td>\n",
       "      <td>0.445901</td>\n",
       "      <td>0.808365</td>\n",
       "      <td>0.709835</td>\n",
       "      <td>0.064335</td>\n",
       "      <td>0.636837</td>\n",
       "      <td>0.815955</td>\n",
       "      <td>0.754486</td>\n",
       "      <td>0.155261</td>\n",
       "      <td>0.380101</td>\n",
       "      <td>0.887176</td>\n",
       "      <td>0.736477</td>\n",
       "      <td>0.110611</td>\n",
       "      <td>0.472199</td>\n",
       "      <td>0.840878</td>\n",
       "      <td>XGB + Morgan+Desc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM + Morgan+MACCS+Desc</td>\n",
       "      <td>0.702322</td>\n",
       "      <td>0.077175</td>\n",
       "      <td>0.558751</td>\n",
       "      <td>0.797771</td>\n",
       "      <td>0.721238</td>\n",
       "      <td>0.081308</td>\n",
       "      <td>0.562819</td>\n",
       "      <td>0.841010</td>\n",
       "      <td>0.724097</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.333358</td>\n",
       "      <td>0.835987</td>\n",
       "      <td>0.734229</td>\n",
       "      <td>0.132705</td>\n",
       "      <td>0.409155</td>\n",
       "      <td>0.869764</td>\n",
       "      <td>LightGBM + Morgan+MACCS+Desc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM + Morgan+Desc</td>\n",
       "      <td>0.673981</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.537913</td>\n",
       "      <td>0.806153</td>\n",
       "      <td>0.742787</td>\n",
       "      <td>0.076318</td>\n",
       "      <td>0.588718</td>\n",
       "      <td>0.834630</td>\n",
       "      <td>0.718914</td>\n",
       "      <td>0.160204</td>\n",
       "      <td>0.285186</td>\n",
       "      <td>0.840819</td>\n",
       "      <td>0.716669</td>\n",
       "      <td>0.176858</td>\n",
       "      <td>0.239009</td>\n",
       "      <td>0.851743</td>\n",
       "      <td>LightGBM + Morgan+Desc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          combo  R2_HOMO_mean  R2_HOMO_std  R2_HOMO_min  \\\n",
       "0   RidgeCV + Morgan+MACCS+Desc      0.682863     0.094272     0.491635   \n",
       "1       XGB + Morgan+MACCS+Desc      0.708732     0.091160     0.529031   \n",
       "2             XGB + Morgan+Desc      0.702562     0.107518     0.445901   \n",
       "3  LightGBM + Morgan+MACCS+Desc      0.702322     0.077175     0.558751   \n",
       "4        LightGBM + Morgan+Desc      0.673981     0.097025     0.537913   \n",
       "\n",
       "   R2_HOMO_max  R2_LUMO_mean  R2_LUMO_std  R2_LUMO_min  R2_LUMO_max  \\\n",
       "0     0.781351      0.715977     0.069319     0.603891     0.803979   \n",
       "1     0.819487      0.712974     0.055788     0.616498     0.810830   \n",
       "2     0.808365      0.709835     0.064335     0.636837     0.815955   \n",
       "3     0.797771      0.721238     0.081308     0.562819     0.841010   \n",
       "4     0.806153      0.742787     0.076318     0.588718     0.834630   \n",
       "\n",
       "   R2_GAP_direct_mean  R2_GAP_direct_std  R2_GAP_direct_min  \\\n",
       "0            0.760879           0.073729           0.649388   \n",
       "1            0.748114           0.144656           0.403224   \n",
       "2            0.754486           0.155261           0.380101   \n",
       "3            0.724097           0.143000           0.333358   \n",
       "4            0.718914           0.160204           0.285186   \n",
       "\n",
       "   R2_GAP_direct_max  R2_GAP_derived_mean  R2_GAP_derived_std  \\\n",
       "0           0.861380             0.755414            0.069041   \n",
       "1           0.866291             0.741622            0.120403   \n",
       "2           0.887176             0.736477            0.110611   \n",
       "3           0.835987             0.734229            0.132705   \n",
       "4           0.840819             0.716669            0.176858   \n",
       "\n",
       "   R2_GAP_derived_min  R2_GAP_derived_max                         model  \\\n",
       "0            0.649388            0.847580   RidgeCV + Morgan+MACCS+Desc   \n",
       "1            0.428436            0.844421       XGB + Morgan+MACCS+Desc   \n",
       "2            0.472199            0.840878             XGB + Morgan+Desc   \n",
       "3            0.409155            0.869764  LightGBM + Morgan+MACCS+Desc   \n",
       "4            0.239009            0.851743        LightGBM + Morgan+Desc   \n",
       "\n",
       "   feature  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================\n",
    "# Multi-seed CV plotting\n",
    "# requires: df_all_results with columns:\n",
    "#   [\"seed\",\"feature\",\"model\",\n",
    "#    \"R2_HOMO\",\"R2_LUMO\",\"R2_GAP_direct\",\"R2_GAP_derived\", ...]\n",
    "# =========================\n",
    "\n",
    "def make_cv_summary_tables(df_all_results):\n",
    "    df = df_all_results.copy()\n",
    "    df[\"combo\"] = df[\"model\"].astype(str) + \" + \" + df[\"feature\"].astype(str)\n",
    "\n",
    "    metrics = [\"R2_HOMO\", \"R2_LUMO\", \"R2_GAP_direct\", \"R2_GAP_derived\"]\n",
    "    grp = df.groupby(\"combo\")[metrics].agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    "    # flatten columns\n",
    "    grp.columns = [f\"{m}_{stat}\" for (m, stat) in grp.columns]\n",
    "    grp = grp.reset_index()\n",
    "\n",
    "    # also keep split-out model/feature for readability\n",
    "    grp[\"model\"] = grp[\"combo\"].str.split(\" + \", n=1).str[0]\n",
    "    grp[\"feature\"] = grp[\"combo\"].str.split(\" + \", n=1).str[1]\n",
    "\n",
    "    # sort by GAP_derived mean (usually what you care about), fallback if missing\n",
    "    sort_key = \"R2_GAP_derived_mean\" if \"R2_GAP_derived_mean\" in grp.columns else \"R2_GAP_direct_mean\"\n",
    "    grp = grp.sort_values(sort_key, ascending=False).reset_index(drop=True)\n",
    "    return grp\n",
    "\n",
    "\n",
    "def plot_cv_boxplots(df_all_results, top_k=20, sort_by=\"mean\"):\n",
    "    \"\"\"\n",
    "    Plot 4 panels (HOMO/LUMO/GAP_direct/GAP_derived) as horizontal boxplots\n",
    "    across seeds, for top_k combos ranked by mean R2 of that target.\n",
    "    \"\"\"\n",
    "    df = df_all_results.copy()\n",
    "    df[\"combo\"] = df[\"model\"].astype(str) + \" + \" + df[\"feature\"].astype(str)\n",
    "\n",
    "    targets = [\n",
    "        (\"R2_HOMO\", \"HOMO\"),\n",
    "        (\"R2_LUMO\", \"LUMO\"),\n",
    "        (\"R2_GAP_direct\", \"GAP (direct)\"),\n",
    "        (\"R2_GAP_derived\", \"GAP (derived: LUMO-HOMO)\"),\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(22, 6), sharey=False)\n",
    "\n",
    "    for ax, (col, title) in zip(axes, targets):\n",
    "        # rank combos for this target\n",
    "        stats = (\n",
    "            df.groupby(\"combo\")[col]\n",
    "            .agg([\"mean\", \"std\"])\n",
    "            .reset_index()\n",
    "            .sort_values(\"mean\", ascending=False)\n",
    "        )\n",
    "\n",
    "        # pick top_k combos\n",
    "        top_combos = stats[\"combo\"].head(top_k).tolist()\n",
    "        sub = df[df[\"combo\"].isin(top_combos)].copy()\n",
    "\n",
    "        # ensure plotting order matches ranking\n",
    "        order = stats.set_index(\"combo\").loc[top_combos].reset_index()[\"combo\"].tolist()\n",
    "\n",
    "        # collect arrays for boxplot\n",
    "        data = [sub[sub[\"combo\"] == c][col].values for c in order]\n",
    "\n",
    "        ax.boxplot(\n",
    "            data,\n",
    "            vert=False,\n",
    "            labels=order,\n",
    "            showmeans=True,\n",
    "            meanline=True,\n",
    "            whis=(5, 95),   # robust whiskers\n",
    "        )\n",
    "        ax.set_title(f\"Multi-seed CV: {title}\\n(top {top_k} by mean R²)\")\n",
    "        ax.set_xlabel(\"R²\")\n",
    "        ax.grid(True, axis=\"x\", alpha=0.25)\n",
    "        # make labels smaller\n",
    "        ax.tick_params(axis=\"y\", labelsize=7)\n",
    "\n",
    "        # add mean values as text (right side)\n",
    "        means = [np.mean(d) if len(d) else np.nan for d in data]\n",
    "        for i, mu in enumerate(means, start=1):\n",
    "            ax.text(mu, i, f\"{mu:.2f}\", va=\"center\", ha=\"left\", fontsize=7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ========= RUN =========\n",
    "# 1) summary table (mean/std) you can inspect or export\n",
    "df_cv_summary = make_cv_summary_tables(df_all_results)\n",
    "display(df_cv_summary.head(5))  \n",
    "\n",
    "# 2) plot: top combos per target\n",
    "#plot_cv_boxplots(df_all_results, top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf84a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# helpers (safe + metrics)\n",
    "# ----------------------------\n",
    "def _safe_clone(est):\n",
    "    try:\n",
    "        return clone(est)\n",
    "    except Exception:\n",
    "        return est.__class__(**est.get_params())\n",
    "\n",
    "\n",
    "def _metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": float(r2_score(y_true, y_pred)),\n",
    "        \"RMSE\": float(mean_squared_error(y_true, y_pred, squared=False)),\n",
    "        \"MAE\": float(mean_absolute_error(y_true, y_pred)),\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_combo(combo_str):\n",
    "    \"\"\"\n",
    "    'Model + FeatureName' -> ('Model', 'FeatureName')\n",
    "    \"\"\"\n",
    "    if not isinstance(combo_str, str) or \" + \" not in combo_str:\n",
    "        raise ValueError(f\"Bad combo string: {combo_str!r} (expected 'Model + Feature').\")\n",
    "    model, feat = combo_str.split(\" + \", 1)\n",
    "    return model.strip(), feat.strip()\n",
    "\n",
    "\n",
    "def oof_predictions_one_model(Xtr, Xte, ytr, est, kfold=5, seed=0):\n",
    "    \"\"\"\n",
    "    Strict OOF:\n",
    "      - OOF preds for train via KFold\n",
    "      - full-train fit preds for test\n",
    "    \"\"\"\n",
    "    Xtr = np.asarray(Xtr)\n",
    "    Xte = np.asarray(Xte)\n",
    "    ytr = np.asarray(ytr).ravel()\n",
    "\n",
    "    kf = KFold(n_splits=kfold, shuffle=True, random_state=seed)\n",
    "    oof = np.zeros(Xtr.shape[0], dtype=float)\n",
    "\n",
    "    for tr_idx, va_idx in kf.split(Xtr):\n",
    "        m = _safe_clone(est)\n",
    "        m.fit(Xtr[tr_idx], ytr[tr_idx])\n",
    "        oof[va_idx] = m.predict(Xtr[va_idx])\n",
    "\n",
    "    m_full = _safe_clone(est)\n",
    "    m_full.fit(Xtr, ytr)\n",
    "    te_pred = m_full.predict(Xte)\n",
    "\n",
    "    return oof, te_pred\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# STRICT stacking (ONE seed)\n",
    "# ----------------------------\n",
    "def strict_stacking_gap_one_seed(\n",
    "    df_all_v,\n",
    "    smiles_col,\n",
    "    targets,\n",
    "    X_morgan_base_all,\n",
    "    X_maccs_all,\n",
    "    X_desc_raw_all,\n",
    "    desc_names,\n",
    "    seed=0,\n",
    "    test_size=0.2,\n",
    "\n",
    "    homo_combo=\"XGB + Morgan+MACCS+Desc\",\n",
    "    lumo_combo=\"LightGBM + Morgan+MACCS+Desc\",\n",
    "\n",
    "    gap_direct_combos=(\"RidgeCV + Morgan+MACCS+Desc\",),\n",
    "\n",
    "    kfold=5,\n",
    "    pca_dim=100,\n",
    "    max_zero_frac=0.99,\n",
    "    var_thresh=1e-12,\n",
    "    corr_thresh=0.95,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      df_gap_compare: per gap combo metrics (direct vs stacked), sorted by R2_stacked desc\n",
    "      pred_bundle   : useful arrays (idx, y, preds)\n",
    "      recipe        : reproducibility info\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- split\n",
    "    N = len(df_all_v)\n",
    "    idx_tr, idx_te = make_train_test_indices(N, seed=seed, test_size=test_size)\n",
    "\n",
    "    # ---------- targets\n",
    "    Ytr, Yte = slice_targets_by_idx(df_all_v, targets, idx_tr, idx_te)\n",
    "    ytr_h = Ytr[\"homo\"].values\n",
    "    ytr_l = Ytr[\"lumo\"].values\n",
    "    ytr_g = Ytr[\"gap\"].values\n",
    "    yte_g = Yte[\"gap\"].values\n",
    "\n",
    "    # ---------- per-seed strict feature prep (train-only fit)\n",
    "    keep_m = fit_binary_feature_filter_on_train(\n",
    "        X_morgan_base_all, idx_tr, zero_var=True, max_zero_frac=max_zero_frac\n",
    "    )\n",
    "    Xtr_m, Xte_m = apply_mask_and_slice(X_morgan_base_all, idx_tr, idx_te, keep_m)\n",
    "\n",
    "    keep_mac = fit_binary_feature_filter_on_train(\n",
    "        X_maccs_all, idx_tr, zero_var=True, max_zero_frac=max_zero_frac\n",
    "    )\n",
    "    Xtr_mac, Xte_mac = apply_mask_and_slice(X_maccs_all, idx_tr, idx_te, keep_mac)\n",
    "\n",
    "    keep_idx_desc, kept_desc_names, scaler_desc = fit_desc_filter_and_scaler_on_train(\n",
    "        X_desc_raw_all, idx_tr, desc_names, var_thresh=var_thresh, corr_thresh=corr_thresh\n",
    "    )\n",
    "    Xtr_desc_s, Xte_desc_s = apply_desc_filter_and_scaler(\n",
    "        X_desc_raw_all, idx_tr, idx_te, keep_idx_desc, scaler_desc\n",
    "    )\n",
    "\n",
    "    # TFIDF strict: fit on TRAIN only\n",
    "    Xtr_self, Xte_self, vec_self, keep_self = fit_selfies_tfidf_on_train(\n",
    "        df_all_v[smiles_col], idx_tr, idx_te,\n",
    "        ngram_range=(2, 5), min_df=2, max_df=0.95,\n",
    "        max_zero_frac=max_zero_frac\n",
    "    )\n",
    "\n",
    "    # 9 fusion feature sets (already sliced)\n",
    "    feature_sets = build_feature_sets_9(\n",
    "        Xtr_m, Xte_m,\n",
    "        Xtr_self, Xte_self,\n",
    "        Xtr_mac, Xte_mac,\n",
    "        Xtr_desc_s, Xte_desc_s,\n",
    "    )\n",
    "\n",
    "    # ---------- model zoo\n",
    "    models = get_model_zoo(seed=seed, pca_dim=pca_dim)\n",
    "\n",
    "    # ---------- base combos for HOMO/LUMO (strict OOF)\n",
    "    homo_model_name, homo_feat_name = parse_combo(homo_combo)\n",
    "    lumo_model_name, lumo_feat_name = parse_combo(lumo_combo)\n",
    "\n",
    "    if homo_model_name not in models:\n",
    "        raise KeyError(f\"HOMO model '{homo_model_name}' not in models: {list(models.keys())}\")\n",
    "    if lumo_model_name not in models:\n",
    "        raise KeyError(f\"LUMO model '{lumo_model_name}' not in models: {list(models.keys())}\")\n",
    "    if homo_feat_name not in feature_sets:\n",
    "        raise KeyError(f\"HOMO feature '{homo_feat_name}' not in feature_sets: {list(feature_sets.keys())}\")\n",
    "    if lumo_feat_name not in feature_sets:\n",
    "        raise KeyError(f\"LUMO feature '{lumo_feat_name}' not in feature_sets: {list(feature_sets.keys())}\")\n",
    "\n",
    "    Xtr_h, Xte_h = feature_sets[homo_feat_name]\n",
    "    Xtr_l, Xte_l = feature_sets[lumo_feat_name]\n",
    "\n",
    "    homo_oof, homo_te = oof_predictions_one_model(\n",
    "        Xtr_h, Xte_h, ytr_h, models[homo_model_name], kfold=kfold, seed=seed\n",
    "    )\n",
    "    lumo_oof, lumo_te = oof_predictions_one_model(\n",
    "        Xtr_l, Xte_l, ytr_l, models[lumo_model_name], kfold=kfold, seed=seed\n",
    "    )\n",
    "\n",
    "    # stacking features (train=OOF; test=full-train preds)\n",
    "    Ztr = np.column_stack([homo_oof, lumo_oof, (lumo_oof - homo_oof)])\n",
    "    Zte = np.column_stack([homo_te,  lumo_te,  (lumo_te  - homo_te )])\n",
    "\n",
    "    # ---------- evaluate each gap candidate\n",
    "    rows = []\n",
    "    pred_details = {}\n",
    "\n",
    "    for combo in gap_direct_combos:\n",
    "        gap_model_name, gap_feat_name = parse_combo(combo)\n",
    "\n",
    "        if gap_model_name not in models:\n",
    "            raise KeyError(f\"GAP model '{gap_model_name}' not in models: {list(models.keys())}\")\n",
    "        if gap_feat_name not in feature_sets:\n",
    "            raise KeyError(f\"GAP feature '{gap_feat_name}' not in feature_sets: {list(feature_sets.keys())}\")\n",
    "\n",
    "        Xtr_g, Xte_g = feature_sets[gap_feat_name]\n",
    "        est_g = models[gap_model_name]\n",
    "\n",
    "        # --- direct\n",
    "        m_direct = _safe_clone(est_g)\n",
    "        m_direct.fit(Xtr_g, ytr_g)\n",
    "        gap_direct_te = m_direct.predict(Xte_g)\n",
    "\n",
    "        # --- stacked (augment with OOF-based Z)\n",
    "        Xtr_aug = np.hstack([Xtr_g, Ztr])\n",
    "        Xte_aug = np.hstack([Xte_g, Zte])\n",
    "\n",
    "        m_stack = _safe_clone(est_g)\n",
    "        m_stack.fit(Xtr_aug, ytr_g)\n",
    "        gap_stacked_te = m_stack.predict(Xte_aug)\n",
    "\n",
    "        md = _metrics(yte_g, gap_direct_te)\n",
    "        ms = _metrics(yte_g, gap_stacked_te)\n",
    "\n",
    "        rows.append({\n",
    "            \"seed\": seed,\n",
    "            \"gap_combo\": combo,\n",
    "            \"gap_model\": gap_model_name,\n",
    "            \"gap_feature\": gap_feat_name,\n",
    "\n",
    "            \"R2_direct\": md[\"R2\"],\n",
    "            \"RMSE_direct\": md[\"RMSE\"],\n",
    "            \"MAE_direct\": md[\"MAE\"],\n",
    "\n",
    "            \"R2_stacked\": ms[\"R2\"],\n",
    "            \"RMSE_stacked\": ms[\"RMSE\"],\n",
    "            \"MAE_stacked\": ms[\"MAE\"],\n",
    "\n",
    "            \"Delta_stack_vs_direct\": ms[\"R2\"] - md[\"R2\"],\n",
    "        })\n",
    "\n",
    "        pred_details[combo] = {\n",
    "            \"gap_direct_te\": gap_direct_te,\n",
    "            \"gap_stacked_te\": gap_stacked_te,\n",
    "        }\n",
    "\n",
    "    df_gap_compare = (\n",
    "        pd.DataFrame(rows)\n",
    "        .sort_values([\"R2_stacked\", \"R2_direct\"], ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    pred_bundle = {\n",
    "        \"idx_tr\": idx_tr,\n",
    "        \"idx_te\": idx_te,\n",
    "        \"yte_gap\": yte_g,\n",
    "        \"homo_oof\": homo_oof,\n",
    "        \"lumo_oof\": lumo_oof,\n",
    "        \"homo_te\": homo_te,\n",
    "        \"lumo_te\": lumo_te,\n",
    "        \"Ztr\": Ztr,\n",
    "        \"Zte\": Zte,\n",
    "        \"gap_preds\": pred_details,\n",
    "    }\n",
    "\n",
    "    recipe = {\n",
    "        \"seed\": seed,\n",
    "        \"test_size\": test_size,\n",
    "        \"kfold\": kfold,\n",
    "        \"homo_combo\": homo_combo,\n",
    "        \"lumo_combo\": lumo_combo,\n",
    "        \"gap_direct_combos\": list(gap_direct_combos),\n",
    "\n",
    "        \"desc_kept_names\": kept_desc_names,\n",
    "        \"morgan_kept_bits\": int(np.sum(keep_m)),\n",
    "        \"maccs_kept_bits\": int(np.sum(keep_mac)),\n",
    "\n",
    "        \"tfidf\": {\n",
    "            \"analyzer\": \"char\",\n",
    "            \"ngram_range\": (2, 5),\n",
    "            \"min_df\": 2,\n",
    "            \"max_df\": 0.95,\n",
    "            \"kept_cols_after_filters\": int(np.sum(keep_self)) if keep_self is not None else None,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return df_gap_compare, pred_bundle, recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6f3b0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>gap_combo</th>\n",
       "      <th>gap_model</th>\n",
       "      <th>gap_feature</th>\n",
       "      <th>R2_direct</th>\n",
       "      <th>RMSE_direct</th>\n",
       "      <th>MAE_direct</th>\n",
       "      <th>R2_stacked</th>\n",
       "      <th>RMSE_stacked</th>\n",
       "      <th>MAE_stacked</th>\n",
       "      <th>Delta_stack_vs_direct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>XGB + Morgan+Desc</td>\n",
       "      <td>XGB</td>\n",
       "      <td>Morgan+Desc</td>\n",
       "      <td>0.851003</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.864148</td>\n",
       "      <td>0.009475</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.013144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>RidgeCV + Morgan+MACCS+Desc</td>\n",
       "      <td>RidgeCV</td>\n",
       "      <td>Morgan+MACCS+Desc</td>\n",
       "      <td>0.797207</td>\n",
       "      <td>0.011577</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.848762</td>\n",
       "      <td>0.009997</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.051555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed                    gap_combo gap_model        gap_feature  R2_direct  \\\n",
       "0     7            XGB + Morgan+Desc       XGB        Morgan+Desc   0.851003   \n",
       "1     7  RidgeCV + Morgan+MACCS+Desc   RidgeCV  Morgan+MACCS+Desc   0.797207   \n",
       "\n",
       "   RMSE_direct  MAE_direct  R2_stacked  RMSE_stacked  MAE_stacked  \\\n",
       "0     0.009923    0.006826    0.864148      0.009475     0.007013   \n",
       "1     0.011577    0.007767    0.848762      0.009997     0.007109   \n",
       "\n",
       "   Delta_stack_vs_direct  \n",
       "0               0.013144  \n",
       "1               0.051555  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 7, 'test_size': 0.2, 'kfold': 5, 'homo_combo': 'XGB + Morgan+MACCS+Desc', 'lumo_combo': 'LightGBM + Morgan+MACCS+Desc', 'gap_direct_combos': ['RidgeCV + Morgan+MACCS+Desc', 'XGB + Morgan+Desc'], 'desc_kept_names': ['MolWt', 'MolLogP', 'TPSA', 'NumHDonors', 'NumHAcceptors', 'NumRotatableBonds', 'RingCount', 'NumAromaticRings', 'FractionCSP3'], 'morgan_kept_bits': 451, 'maccs_kept_bits': 105, 'tfidf': {'analyzer': 'char', 'ngram_range': (2, 5), 'min_df': 2, 'max_df': 0.95, 'kept_cols_after_filters': 483}}\n"
     ]
    }
   ],
   "source": [
    "df_gap_compare, pred_bundle, recipe = strict_stacking_gap_one_seed(\n",
    "    df_all_v=df_all_v,\n",
    "    smiles_col=\"smiles\",\n",
    "    targets=[\"homo\",\"lumo\",\"gap\"],\n",
    "    X_morgan_base_all=X_morgan_base_all,\n",
    "    X_maccs_all=X_maccs_all,\n",
    "    X_desc_raw_all=X_desc_raw_all,\n",
    "    desc_names=desc_names,\n",
    "\n",
    "    seed=7,\n",
    "    test_size=0.2,\n",
    "\n",
    "    homo_combo=\"XGB + Morgan+MACCS+Desc\",\n",
    "    lumo_combo=\"LightGBM + Morgan+MACCS+Desc\",\n",
    "\n",
    "    gap_direct_combos=(\n",
    "        \"RidgeCV + Morgan+MACCS+Desc\",\n",
    "        \"XGB + Morgan+Desc\",\n",
    "    ),\n",
    "\n",
    "    kfold=5,\n",
    ")\n",
    "\n",
    "display(df_gap_compare)\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a83105d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_gap_model_strict(\n",
    "    df_all_v,\n",
    "    X_morgan_base_all,\n",
    "    X_maccs_all,\n",
    "    X_desc_raw_all,\n",
    "    desc_names,\n",
    "    combo,                # e.g. \"XGB + Morgan+Desc\"\n",
    "    kfold=5,\n",
    "    seed=0,\n",
    "    max_zero_frac=0.99,\n",
    "    var_thresh=1e-12,\n",
    "    corr_thresh=0.95,\n",
    "    pca_dim=100,\n",
    "):\n",
    "    \"\"\"\n",
    "    Strict CV:\n",
    "      every fold re-fits feature filters + scaler on TRAIN ONLY\n",
    "    \"\"\"\n",
    "\n",
    "    model_name, feat_name = combo.split(\" + \", 1)\n",
    "\n",
    "    models = get_model_zoo(seed=seed, pca_dim=pca_dim)\n",
    "    est = models[model_name]\n",
    "\n",
    "    y = df_all_v[\"gap\"].values\n",
    "    N = len(y)\n",
    "\n",
    "    kf = KFold(n_splits=kfold, shuffle=True, random_state=seed)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for fold, (tr, te) in enumerate(kf.split(np.arange(N))):\n",
    "\n",
    "        # ---- Morgan\n",
    "        keep_m = fit_binary_feature_filter_on_train(X_morgan_base_all, tr, True, max_zero_frac)\n",
    "        Xm_tr, Xm_te = apply_mask_and_slice(X_morgan_base_all, tr, te, keep_m)\n",
    "\n",
    "        # ---- MACCS\n",
    "        keep_mac = fit_binary_feature_filter_on_train(X_maccs_all, tr, True, max_zero_frac)\n",
    "        Xmac_tr, Xmac_te = apply_mask_and_slice(X_maccs_all, tr, te, keep_mac)\n",
    "\n",
    "        # ---- Desc\n",
    "        keep_desc, kept_names, scaler = fit_desc_filter_and_scaler_on_train(\n",
    "            X_desc_raw_all, tr, desc_names, var_thresh, corr_thresh\n",
    "        )\n",
    "        Xd_tr, Xd_te = apply_desc_filter_and_scaler(X_desc_raw_all, tr, te, keep_desc, scaler)\n",
    "\n",
    "        # ---- build feature\n",
    "        if feat_name == \"Morgan+Desc\":\n",
    "            Xtr = np.hstack([Xm_tr, Xd_tr])\n",
    "            Xte = np.hstack([Xm_te, Xd_te])\n",
    "\n",
    "        elif feat_name == \"Morgan+MACCS+Desc\":\n",
    "            Xtr = np.hstack([Xm_tr, Xmac_tr, Xd_tr])\n",
    "            Xte = np.hstack([Xm_te, Xmac_te, Xd_te])\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported feature: {feat_name}\")\n",
    "\n",
    "        ytr = y[tr]\n",
    "        yte = y[te]\n",
    "\n",
    "        m = _safe_clone(est)\n",
    "        m.fit(Xtr, ytr)\n",
    "        p = m.predict(Xte)\n",
    "\n",
    "        rows.append({\n",
    "            \"fold\": fold,\n",
    "            \"R2\": r2_score(yte, p),\n",
    "            \"RMSE\": mean_squared_error(yte, p, squared=False),\n",
    "            \"MAE\": mean_absolute_error(yte, p),\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    summary = (\n",
    "        df[[\"R2\",\"RMSE\",\"MAE\"]]\n",
    "        .agg([\"mean\",\"std\",\"min\",\"max\"])\n",
    "        .T\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\":\"metric\"})\n",
    "    )\n",
    "\n",
    "    return df, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40e3a583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB + Morgan+Desc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.791914</td>\n",
       "      <td>0.065915</td>\n",
       "      <td>0.693990</td>\n",
       "      <td>0.877180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.008993</td>\n",
       "      <td>0.014224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.007751</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.009957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric      mean       std       min       max\n",
       "0     R2  0.791914  0.065915  0.693990  0.877180\n",
       "1   RMSE  0.011478  0.002409  0.008993  0.014224\n",
       "2    MAE  0.007751  0.001665  0.006132  0.009957"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCV + Morgan+MACCS+Desc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.781446</td>\n",
       "      <td>0.076348</td>\n",
       "      <td>0.656660</td>\n",
       "      <td>0.861380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.011894</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.016873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.008157</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>0.012052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric      mean       std       min       max\n",
       "0     R2  0.781446  0.076348  0.656660  0.861380\n",
       "1   RMSE  0.011894  0.003409  0.009199  0.016873\n",
       "2    MAE  0.008157  0.002476  0.006355  0.012052"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_xgb, sum_xgb = cv_gap_model_strict(\n",
    "    df_all_v,\n",
    "    X_morgan_base_all,\n",
    "    X_maccs_all,\n",
    "    X_desc_raw_all,\n",
    "    desc_names,\n",
    "    combo=\"XGB + Morgan+Desc\",\n",
    "    kfold=5,\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "df_ridge, sum_ridge = cv_gap_model_strict(\n",
    "    df_all_v,\n",
    "    X_morgan_base_all,\n",
    "    X_maccs_all,\n",
    "    X_desc_raw_all,\n",
    "    desc_names,\n",
    "    combo=\"RidgeCV + Morgan+MACCS+Desc\",\n",
    "    kfold=5,\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "print(\"XGB + Morgan+Desc\")\n",
    "display(sum_xgb)\n",
    "\n",
    "print(\"RidgeCV + Morgan+MACCS+Desc\")\n",
    "display(sum_ridge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chemml)",
   "language": "python",
   "name": "chemml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
